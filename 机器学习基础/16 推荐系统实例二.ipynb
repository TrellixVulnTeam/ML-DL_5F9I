{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐系统冷启动问题\n",
    "推荐系统的先决条件是有大量的用户数据。在没有大量用户数据的情况下设计个性化推荐系统并且让用户对推荐结果满意从而愿意使用推荐系统，就是**冷启动的问题**。\n",
    "## 冷启动问题简介\n",
    "冷启动问题（cold start）主要分3类：\n",
    "1）**用户冷启动** 用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣， 从而无法借此给他做个性化推荐。 \n",
    "\n",
    "2）**物品冷启动** 物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。\n",
    "\n",
    "3）**系统冷启动** 系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发 布时就让用户体验到个性化推荐服务这一问题。 \n",
    "\n",
    "对于这3种不同的冷启动问题，有不同的解决方案：\n",
    "\n",
    "1）提供非个性化的推荐 非个性化推荐的最简单例子就是热门排行榜，等到用户数据收集到一定的时候，再切换为个性化推荐。 \n",
    "\n",
    "2）利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。 还有生日、邮编、职业、民族、学历和居住地等，这样可以让用户与自己更加相关的推荐。\n",
    "\n",
    "3）利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。 \n",
    "\n",
    "4）要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。 \n",
    "\n",
    "5）对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。 \n",
    "\n",
    "6）在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。 \n",
    "\n",
    "下面几节将详细描述其中的某些方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于用户注册信息\n",
    "基于注册信息的个性化推荐流程基本如下： \n",
    "\n",
    "1. 获取用户的注册信息； \n",
    "\n",
    "2. 根据用户的注册信息对用户分类； \n",
    "\n",
    "3. 给用户推荐他所属分类中用户喜欢的物品。\n",
    "\n",
    "基于用户注册信息的**推荐算法其核心问题是计算每种特征的用户喜欢的物品**。也就是说，对于每种特征f，计算具有这种特征的用户对各个物品的喜好程度p(f, i)。p(f, i)可以简单地定义为物品i在具有f的特征的用户中的热门程度：$$p(f,i)=|N(i)\\cap U(f)|$$$N(i)$为喜欢物品i的用户集合，$U(f)$为具有特征f的用户的集合。\n",
    "\n",
    "上面这种定义可以比较准确地预测具有某种特征的用户是否喜欢某个物品。但是，在这种定义下，往往**热门的物品**会在各种特征的用户中都具有比较高的权重。也就是说具有比较高的$|N(i)|$的物品会在每一类用户中都有比较高的$p(f,i)$。给用户推荐热门物品并不是推荐系统的主要任务，**推荐系统应该帮助用户发现他们不容易发现的物品**。因此，我们可以将$p(f,i)$定义为喜欢物品i的用户中具有特征f的比例：$$p(f,i)=\\frac{|N(i)\\cap U(f)|}{|N(i)|+a}$$分母中使用参数$a$的目的是解决数据稀疏问题。为分母加上一个比较大的数，可以避免物品产生比较大的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择合适的物品启动用户的兴趣\n",
    "解决用户冷启动问题的另一个方法是在新用户第一次访问推荐系统时，不立即给用户展示推荐结果，而是给用户提供一些物品，让用户反馈他们对这些物品的兴趣，然后根据用户反馈提供个性化推荐。很多推荐系统采取了这种方式来解决用户冷启动问题。\n",
    "\n",
    "一般来说，能够用来启动用户兴趣的物品需要具有以下特点。 1）比较热门；2）具有代表性和区分性;3)启动物品集合需要有多样性。\n",
    "\n",
    "如何设计一个选择启动物品集合的系统呢？Nadav Golbandi探讨了这个问题，提出可以用一个**决策树**解决这个问题。\n",
    "\n",
    "首先，给定一群用户，Nadav Golbandi用这群用户对物品评分的方差度量这群用户兴趣的一致程度。如果方差很大，说明这一群用户的兴趣不太一致，反之则说明这群用户的兴趣比较一致。令$\\sigma_u\\in U'$为用户集合$U'$中所有评分的方差，Nadav Golbandi的基本思想是通过如下方式度量一个物品的区分度$D(i)$:$$D(i)=\\sigma_{u\\in N^+(i)}+\\sigma_{u\\in N^-(i)}+\\sigma_{u\\in \\bar N(i)}$$ 其中，$N^+(i)$是喜欢物品i的用户集合，$N^-(i)$是不喜欢物品i的用户集合，$\\bar N(i)$是没有对物品i评分的用户集合,$\\sigma$是对应的评分的方差。\n",
    "\n",
    "也就是说，对于物品i，Nadav Golbandi将用户分成3类——喜欢物品i的用户、不喜欢物品i的用户和不知道物品i的用户（即没有给i评分的用户）。如果这3类用户集合内的用户对其他的物品兴趣很不一致，说明物品i具有较高的区分度。\n",
    "\n",
    "Nadav Golbandi的算法首先会从所有用户中找到具有最高区分度的物品i，然后将用户分成3 类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为3类，也就是将总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而可以开始对用户进行比较准确地个性化推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用物品的内容信息 \n",
    "**物品冷启动**需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户。物品冷启动在新闻网站等时效性很强的网站中非常重要，因为那些网站中时时刻刻都有新加入的物品，而且每个物品必须能够在第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。\n",
    "\n",
    "第2章介绍了两种主要的推荐算法——**UserCF和ItemCF算法**。首先需要指出的是，UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，会首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。在很多网站中，推荐列表并不是给用户展示内容的唯一列表，那么当一个新物品加入时，总会有用户从某些途径看到这些物品，对这些物品产生反馈。那么，当一个用户对某个物品产生反馈后，和他历史兴趣相似的其他用户的推荐列表中就有可能出现这一物品，从而更多的人就会对这个物品产生反馈，导致更多的人的推荐列表中会出现这一物品，因此该物品就能不断地扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中。 \n",
    "\n",
    "但是，有些网站中推荐列表可能是用户获取信息的主要途径，比如豆瓣网络电台。那么对于UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新的物品。只要有一小部分人能够发现并喜欢新的物品，UserCF算法就能将这些物品扩散到更多的用户中。解决第一推动力最简单的方法是**将新的物品随机展示给用户**，但这样显然不太个性化，因此可以考虑利用物品的内容信息，**将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户**。\n",
    "\n",
    "对于**ItemCF算法**来说，物品冷启动就是一个严重的问题了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。ItemCF算法会每隔一段时间利用用户行为计算物品相似度表（一般一天计算一次），在线服务时ItemCF算法会将之前计算好的物品相关度矩阵放在内存中。因此，当新物品加入时，内存中的物品相关表中不会存在这个物品，从而ItemCF算法无法推荐新的物品。解决这一问题的办法是**频繁更新物品相似度表**，但基于用户行为计算物品相似度是非常耗时的事情，主要原因是用户行为日志非常庞大。而且，新物品如果不展示给用户，用户就无法对它产生行为，通过行为日志计算是计算不出包含新物品的相关矩阵的。为此，我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表（比如半小时计算一次）。 \n",
    "\n",
    "**物品的内容信息**多种多样，不同类型的物品有不同的内容信息。如下图：![jupyter](./recommend-2-1.png)一般来说，物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个**关键词向量**。如果物品的内容是是文本的形式，则需要引入一些理解自然语言的技术**抽取关键词**。下图展示了从文本生成关键词向量的主要步骤。对于中文，首先要对文本进行**分词**，将字流变成词流，然后从词流中检测出命名实体（如人名、地名、组织名等），这些实体和一些其他重要的词将组成关键词集合，最后对关键词进行**排名**，计算每个关键词的**权重**，从而生成**关键词向量**。![jupyter](./recommend-2-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于物品d，它的内容表示成一个**关键词向量**：$$d_i=\\{(e_1,w_1),(e_2,w_2),L\\}$$其中$e_i$关键词，$w_i$是关键词的权重。权重可以用**TF-IDF公式计算**：$$w_i=\\frac{TF(e_i)}{logDF(e_i)}$$在给定物品内容的关键词向量后，物品的**内容相似度**可以通过向量之间的**余弦相似度计算**：$$w_{ij}=\\frac{d_i*d_j}{\\sqrt{\\parallel d_i\\parallel\\parallel d_j\\parallel}}$$这种算法的时间复杂度很高。假设有N个物品，每个物品平均由m个实体表示，那么这个算法的复杂度是$O(N^2m)$。\n",
    "\n",
    "在实际应用中，可以首先通过建立**关键词—物品的倒排表**加速这一计算过程，这一方法已经在前面介绍UserCF和ItemCF算法时详细介绍过了。\n",
    "\n",
    "向量空间模型在内容数据丰富时可以获得比较好的效果。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，**如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度**。举个例子，假设有两篇论文，它们的标题分别是“推荐系统的动态特性”和“基于时间的协同过滤算法研究”。如果读者对推荐系统很熟悉，可以知道这两篇文章的研究方向是类似的，但是它们标题中没有一样的关键词。其实，它们的关键词虽然不同，但却是相似的。“动态”和“基于时间”含义相似，“协同过滤”是“推荐系统”的一种算法。换句话说，这两篇文章的关键词虽然不同，但**关键词所属的话题是相同的**。在这种情况下，首先需要知道文章的**话题分布**，然后才能准确地计算文章的相似度。如何建立**文章、话题和关键词**的关系是**话题模型**（topic model）研究的重点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代表性的话题模型LDA\n",
    "LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的**基本思想**是，一个人在写一篇**文档**的时候，会首先想这篇文章要讨论哪些**话题**，然后思考这些话题应该用什么**词**描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。 \n",
    "\n",
    "LDA中有3种元素，即**文档、话题和词语**。每一篇文档都会表现为词的集合，这称为**词袋模型**(bag of words)。每个词在一篇文章中属于一个话题。令D为文档集合，D[i]是第i篇文档。w[i][j]是第i篇文档中的第j个词。z[i][j]是第i篇文档中第j个词属于的话题。\n",
    "\n",
    "**LDA的计算过程**包括初始化和迭代两部分。首先要对z进行初始化，而初始化的方法很简单，假设一共有K个话题，那么对第i篇文章中的第j个词，可以随机给它赋予一个话题。同时，用NWZ(w, z)记录词w被赋予话题z的次数，NZD(z,d)记录文档d中被赋予话题z的词的个数。![jupyter](./recommend-2-3.png)在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。伪代码如下所示：![jupyter](./recommend-2-4.png)LDA可以很好地将词组合成不同的话题。\n",
    "\n",
    "在使用LDA计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后**利用两个物品的话题分布计算物品的相似度**。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。**计算分布的相似度可以利用KL散度**：$$D_{KL}(p\\parallel q)=\\sum_ip(i)ln\\frac{p(i)}{q(i)}$$其中p和q是两个分布，KL散度越大说明分布的相似度越低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 发挥专家的作用 \n",
    "很多推荐系统在建立时，既没有用户的行为数据，也没有充足的物品内容信息来计算准确的物品相似度。为了在推荐系统建立时就让用户得到比较好的体验，很多系统都**利用专家进行标注**。这方面的代表系统是个性化网络电台Pandora和电影推荐网站Jinni。 \n",
    "\n",
    "Pandora是一个给用户播放音乐的个性化电台应用。众所周知，计算音乐之间的相似度是比较困难的。首先，音乐是多媒体，如果从音频分析入手计算歌曲之间的相似度，则技术门槛很高，而且也很难计算得令人满意。其次，仅仅利用歌曲的专辑、歌手等属性信息很难获得令人满意的歌曲相似度表，因为一名歌手、一部专辑往往只有一两首好歌。为了解决这个问题，Pandora雇用了一批懂计算机的音乐人进行了一项称为**音乐基因的项目**。他们听了几万名歌手的歌，并对这些歌的各个维度进行标注。最终，他们使用了**400多个特征**（Pandora**称这些特征为基因**）。标注完所有的歌曲后，每首歌都可以表示为一个400维的向量，然后通过常见的向量相似度算法可以计算出歌曲的相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用用户标签数据\n",
    "推荐系统的目的是联系用户的兴趣和物品，这种联系需要依赖不同的媒介。GroupLens表示目前流行的推荐系统基本上通过3种方式联系用户兴趣和物品。第一种方式是利用用户喜欢过的物品，给用户推荐与他喜欢过的物品相似的物品，这就 是前面提到的**基于物品的算法**。第二种方式是利用和用户兴趣相似的其他用户，给用户推荐 那些和他们兴趣爱好相似的其他用户喜欢的物品，这是前面提到的**基于用户的算法**。除了这 两种方法，第三种重要的方式是**通过一些特征（feature）联系用户和物品**，给用户推荐那些 具有用户喜欢的特征的物品。这里的特征有不同的表现方式，比如可以表现为物品的属性集合（比如对于图书，属性集合包括作者、出版社、主题和关键词等），也可以表现为隐语义向量（latent factor vector），这可以通过前面提出的隐语义模型习得到。本章将讨论一种重要的特征表现方式——**标签**。\n",
    "\n",
    "**标签**是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。根据给物品打标签的人的不同，**标签应用一般分为两种**：一种是让作者或者专家给物品打标签；另一种是让普通用户给物品打标签，也就是UGC（User Generated Content，用户生成的内容）的标签应用。UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的语义，从而将用户和物品联系了起来。因此本章主要讨论UGC的标签应 用，研究用户给物品打标签的行为，探讨如何通过分析这种行为给用户进行个性化推荐。\n",
    "\n",
    "UGC 标签系统的代表应用**Delicous**可算是标签系统里的开山鼻祖，它允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网。\n",
    "\n",
    "**CiteULike**是一个著名的论文书签网站，它允许研究人员提交或者收藏自己感兴趣的论文并且 给论文打标签，从而帮助用户更好地发现和自己研究领域相关的优秀论文。\n",
    "\n",
    "**Last.fm**是一家著名的音乐网站，它通过分析用户的听歌行为预测用户对音乐的兴趣，从而给 用户推荐个性化的音乐。作为多媒体，音乐不像文本那样可以很容易地分析内容信息。为了 在不进行复杂音频分析的情况下获得音乐的内容信息，Last.fm引入了UGC标签系统，让用户 用标签标记音乐和歌手。\n",
    "\n",
    "**豆瓣**是中国著名的评论和社交网站，同时也是中国个性化推荐领域的领军企业之一。豆瓣在个性化推荐领域进行了广泛尝试，标签系统也是其尝试的领域之一。它允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义，并用这种信息改善推荐效果。\n",
    "\n",
    "**Hulu**是美国著名的视频网站。视频作为一种最为复杂的多媒体，获取它的内容信息是最困难 的，因此Hulu也引入了用户标签系统来让用户对电视剧和电影进行标记。图4-7展示了美剧 《豪斯医生》的常用标签，可以看到，Hulu对标签做了分类并展示了每一类最热门的标签。 从类型（Genre）看，《豪斯医生》是一部医学片（medical）；从时间看，这部剧开始于 2004年；从人物看，这部美剧的主演是hugh laurie，他在剧中饰演的人物是greg house。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签系统中的推荐问题 \n",
    "打标签作为一种重要的用户行为，蕴含了很多用户兴趣信息，因此深入研究和利用用户打标签的行为可以很好地指导我们改进个性化推荐系统的推荐质量。同时，标签的表示形式非常简单，便于很多算法处理。 \n",
    "\n",
    "标签系统中的**推荐问题主要有以下两个**。 \n",
    "\n",
    "如何利用用户打标签的行为为其推荐物品（基于标签的推荐）？ \n",
    "\n",
    "如何在用户给物品打标签时为其推荐适合该物品的标签（标签推荐）？ \n",
    "\n",
    "为了研究上面的两个问题，我们首先需要解答下面3个问题。 \n",
    "\n",
    "用户为什么要打标签？ \n",
    "\n",
    "用户怎么打标签？ \n",
    "\n",
    "用户打什么样的标签？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于标签的推荐系统 \n",
    "如何利用用户的标签数据提高个性化推荐结果的质量是推荐系统研究的重要课题。豆瓣很好地利用了标签数据，它将标签系统融入到了整个产品线中。**首先**，在每本书的页面上，豆瓣都提供了一个叫做“豆瓣成员常用标签”的应用，它给出了这本书上用户最常打的标签。**同时**，在用户给书做评价时，豆瓣也会让用户给图书打标签。**最后**，在最终的个性化推荐结果里，豆瓣利用标签将用户的推荐结果做了**聚类**，显示了对不同标签下用户的推荐结果，从而增加了推荐的多样性和可解释性。 \n",
    "\n",
    "一个用户标签行为的数据集一般由一个**三元组的集合表示**，其中**记录**$(u, i, b)$表示用户u给物品i打上了标签b。当然，用户的真实标签行为数据远远比三元组表示的要复杂，比如用户打标签的时间、用户的属性数据、物品的属性数据等。但是本章只考虑上面定义的三元组形式的数据**(用户、物 品、标签)**表示。 \n",
    "\n",
    "本章将采用两个不同的数据集评测基于标签的物品推荐算法。一个是**Delicious数据集**，另一 个是**CiteULike数据集**。Delicious数据集中包含用户对网页的标签记录。它每一行由4部分组成，即**时间、用户ID、网页URL、标签**。本章只抽取了其中用户对一些著名博客网站网页 （Wordpress、BlogSpot、TechCrunch）的标签记录。**CiteULike数据集**包含用户对论文的标签 记录，它每行也由4部分组成，即**物品ID、用户ID、时间、标签**，本章选取了其中稠密的部 分。\n",
    "\n",
    "Delicious数据集http://www.dai-labor.de/en/competence_centers/irml/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验设置\n",
    "本节将数据集随机分成10份。这里分割的**键值是用户和物品，不包括标签**。挑选1份作为测试集，剩下的9份作为训练集，通过学习训练集中的用户标签数据预测测试集上用户会给什么物品打标签。对于用户u，令**R(u)**为给用户u的长度为N的推荐列表，里面包含我们认为用户会打标签的物品。令**T(u)**是测试集中用户u实际上打过标签的物品集合。然后，我们利用**准确率（precision）和召回率（recall）**评测个性化推荐算法的精度。$$Precision=\\frac{|R(u)\\cap T(u)|}{|R(u)|}$$$$Recall=\\frac{|R(u)\\cap T(u)|}{|T(u)|}$$\n",
    "覆盖率（coverage）、多样性 （diversity）和新颖度:$$Coverage=\\frac{|\\cup_{u\\in U}R(u)|}{|I}$$\n",
    "在得到物品之间的相似度度量后，我们通过如下公式计算一个推荐列表的多样性![jupyter](./recommend-2-5.png)至于推荐结果的新颖性，我们简单地用推荐结果的平均热门程度（AveragePopularity）度量。对于物品i，定义它的流行度item_pop(i)为给这个物品打过标签的用户数。而对推荐 系统，我们定义它的平均热门度如下：![jupyter](./recommend-2-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个最简单的算法 \n",
    "算法描述如下:\n",
    "\n",
    "统计每个用户最常用的标签。\n",
    "\n",
    "对于每个标签，统计被打过这个标签次数最多的物品。 \n",
    "\n",
    "对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。 \n",
    "\n",
    "对于上面的算法，用户u对物品i的兴趣公式如下：$$p(u,i)=\\sum_bn_{u,b}n_{b,i}$$$n_{u,b}$是用户打过标签b的次数，$n_{b,i}$是物品i被打过标签b的次数。\n",
    "\n",
    "假设我们拥有一组音乐数据，每行是三元组，如下所示：![jupyter](./recommend-2-6.png)用 \n",
    "records存储标签数据的三元组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', '一曲相思', '流行'],\n",
       " ['A', '生僻字', '流行'],\n",
       " ['A', '最后的莫西干人', '纯音乐'],\n",
       " ['A', '倩女幽魂', '经典'],\n",
       " ['B', '故乡的原风景', '纯音乐'],\n",
       " ['B', '生僻字', '流行'],\n",
       " ['B', '故乡的原风景', '纯音乐'],\n",
       " ['C', '倩女幽魂', '经典'],\n",
       " ['C', '海阔天空', '经典'],\n",
       " ['D', '海阔天空', '经典'],\n",
       " ['A', '突然好想你', '寂寞'],\n",
       " ['C', '走西口', '民歌'],\n",
       " ['D', '走西口', '民歌'],\n",
       " ['B', '重头再来', '励志'],\n",
       " ['D', '倩女幽魂', '经典'],\n",
       " ['C', '重头再来', '励志'],\n",
       " ['D', '最后的莫西干人', '纯音乐']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records=[['A', '一曲相思', '流行'], ['A', '生僻字', '流行'], ['A', '最后的莫西干人', '纯音乐'], ['A', '倩女幽魂', '经典'], ['B', '故乡的原风景', '纯音乐'], ['B', '生僻字', '流行'], ['B', '故乡的原风景', '纯音乐'], ['C', '倩女幽魂', '经典'], ['C', '海阔天空', '经典'], ['D', '海阔天空', '经典'], ['A', '突然好想你', '寂寞'], ['C', '走西口', '民歌'], ['D', '走西口', '民歌'], ['B', '重头再来', '励志'], ['D', '倩女幽魂', '经典'], ['C', '重头再来', '励志'], ['D', '最后的莫西干人', '纯音乐']]\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计出 user_tags和user_tags。其中user_tags是$n_{u,b}$，tag_items是$n_{b,i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': {'流行': 2, '纯音乐': 1, '经典': 1, '寂寞': 1},\n",
       "  'B': {'纯音乐': 2, '流行': 1, '励志': 1},\n",
       "  'C': {'经典': 2, '民歌': 1, '励志': 1},\n",
       "  'D': {'经典': 2, '民歌': 1, '纯音乐': 1}},\n",
       " {'流行': {'一曲相思': 1, '生僻字': 2},\n",
       "  '纯音乐': {'最后的莫西干人': 2, '故乡的原风景': 2},\n",
       "  '经典': {'倩女幽魂': 3, '海阔天空': 2},\n",
       "  '寂寞': {'突然好想你': 1},\n",
       "  '民歌': {'走西口': 2},\n",
       "  '励志': {'重头再来': 2}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def InitStat(records):\n",
    "    user_tags = dict()  # 用户打过标签的次数\n",
    "    tag_items = dict()  # 音乐被打过标签的次数，代表歌曲流行度\n",
    "\n",
    "    for user, item, tag in records:\n",
    "        user_tags.setdefault(user, dict()) \n",
    "        user_tags[user].setdefault(tag, 0)\n",
    "        user_tags[user][tag] += 1\n",
    "\n",
    "        tag_items.setdefault(tag, dict())\n",
    "        tag_items[tag].setdefault(item, 0)\n",
    "        tag_items[tag][item] += 1\n",
    "   \n",
    "    #print(\"用户打过标签的次数: \", user_tags)\n",
    "    #print(\"音乐打过标签的次数: \", tag_items)         \n",
    "    \n",
    "    return user_tags, tag_items\n",
    "InitStat(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面获得的数据统计，那么我们就可以根据用户对歌曲的兴趣来为用户**推荐歌曲**，兴趣度越大，越被优先推荐。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户对歌曲兴趣度:  [('生僻字', 4), ('倩女幽魂', 3), ('一曲相思', 2), ('最后的莫西干人', 2), ('故乡的原风景', 2), ('海阔天空', 2), ('突然好想你', 1)]\n",
      "\n",
      "为用户推荐歌曲:  生僻字\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fc88452e30b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmusic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0muser_tags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_items\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mInitStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mRecommend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-fc88452e30b8>\u001b[0m in \u001b[0;36mRecommend\u001b[1;34m(user, K)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmusic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmusic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmusic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmusic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "def Recommend(user, K):\n",
    "    recommend_items = dict()\n",
    "    for tag, wut in user_tags[user].items():\n",
    "        for item, wti in tag_items[tag].items():\n",
    "            if item not in recommend_items:\n",
    "                recommend_items[item] = wut * wti    # 计算用户对物品兴趣度\n",
    "            else:\n",
    "                recommend_items[item] += wut * wti\n",
    "    \n",
    "    rec = sorted(recommend_items.items(),key = lambda x:x[1],reverse = True)   # 将推荐歌曲按兴趣度排名\n",
    "    print(\"用户对歌曲兴趣度: \", rec)\n",
    "    music = []\n",
    "    for i in range(K):\n",
    "        music.append(rec[i][0])\n",
    "\n",
    "        music = \"/\".join(music)\n",
    "        print(\"\\n为用户推荐歌曲: \", music)\n",
    "    return music\n",
    "user_tags, tag_items=InitStat(records)\n",
    "Recommend(\"A\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法改进\n",
    "推荐完成后，回顾一下，发现一个问题，如果新出的一首流行歌，举个例子，比如说《生僻字》，这首歌可能很多人都听过，也都打了标签，那么$n_{b,i}$就非常大，那么即使$n_{u,b}$很小，用户对《生僻字》的兴趣度也会很大，就很有可能发生推荐错误的情况。\n",
    "   \n",
    "所以上面这种推荐算法**给热门标签对应的热门物品很大的权重，因此会造成推荐热门的物品给用户，从而降低推荐结果的新颖性**。另外，这个公式利用用户的标签向量对用户兴趣建模，其中每个标签都是用户使用过的标签，而标签的权重是用户使用该标签的次数。这种建模方法的**缺点**是给热门标签过大的权重，从而不能反应用户个性化的兴趣。这里我们可以借鉴TF-IDF的思想，对这一公式进行改进，提出TagBasedTFIDF算法：![jupyter](./recommend-2-8.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
