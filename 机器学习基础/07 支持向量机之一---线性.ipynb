{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "\n",
    "统计学习方法，李航博士\n",
    "\n",
    "https://cuijiahua.com/blog/2017/11/ml_8_svm_1.html\n",
    "# 什么是支持向量机SVM？\n",
    "支持向量机SVM的英文全称是Support Vector Machines，是用于分类的一种算法。![jupyter](./img/SVM1-1.png)\n",
    "\n",
    "如图是平面上分类小球的问题。如果是线性可分的，即用一根棍就可以将两种小球分开的时候，我们只要将棍的位置放在让小球距离棍的距离最大化的位置即可，寻找这个**最大间隔**的过程，就叫做**最优化**。但是，现实往往是很残酷的，一般的数据是线性不可分的，也就是找不到一个棍将两种小球很好的分类（如下图）。这个时候，我们就需要像大侠一样，将小球拍起，用一张纸代替小棍将小球进行分类。想要让数据飞起，我们需要的东西就是核函数(kernel)，用于切分小球的纸，就是超平面。![jupyter](./img/SVM1-2.png)\n",
    "\n",
    "根据上面的描述，问题**从线性可分（上图）延伸到线性不可分（下图）**。下面进行支持向量机的原理性剖析。本部分介绍线性可分，下一部分介绍线性不可分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性SVM\n",
    "先看下线性可分的二分类问题。![jupyter](./img/SVM1-3.jpg)上图中的(a)是已有的数据，红色和蓝色分别代表两个不同的类别。数据显然是线性可分的，但是将两类数据点分开的直线显然不止一条。上图的(b)和(c)分别给出了B、C两种不同的分类方案，其中黑色实线为分界线，术语称为“**决策面**”。每个决策面对应了一个线性分类器。虽然从分类结果上看，分类器A和分类器B的效果是相同的。但是他们的性能是有差距的，看下图：![jupyter](./img/SVM1-4.jpg)在\"决策面\"不变的情况下，我又**添加了一个红点**。可以看到，分类器B依然能很好的分类结果，而分类器C则出现了分类错误。显然分类器B的\"决策面\"放置的位置优于分类器C的\"决策面\"放置的位置，SVM算法也是这么认为的，它的依据就是分类器B的分类间隔比分类器C的分类间隔大。这里涉及到第一个SVM独有的概念**\"分类间隔\"**。\n",
    "\n",
    "在保证决策面方向不变且不会出现错分样本的情况下移动决策面，会在原来的决策面两侧找到两个极限位置（越过该位置就会产生错分现象），如虚线所示。**虚线的位置由决策面的方向和距离原决策面最近的几个样本的位置决定**。而这两条平行虚线**正中间**的分界线就是在保持当前决策面方向不变的前提下的最优决策面。两条虚线之间的垂直距离就是这个最优决策面对应的**分类间隔**。显然每一个可能把数据集正确分开的方向都有一个最优决策面（有些方向无论如何移动决策面的位置也不可能将两类样本完全分开），而不同方向的最优决策面的分类间隔通常是不同的，那个具有**“最大间隔”**的决策面就是SVM要寻找的最优解。而这个真正的最优解对应的两侧虚线所穿过的样本点，就是SVM中的支持样本点，称为**\"支持向量\"**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（1）线性可分支持向量机**\n",
    "\n",
    "给定线性可分数据集，通过间隔最大化或等价地求解凸二次规划问题学习得到得分离超平面为$$w^*\\cdot x+b^*=0$$\n",
    "以及相应得分类函数$$f(x)=sign(w^*\\cdot x +b^*)$$称为线性可分支持向量机。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（2）函数间隔**\n",
    "\n",
    "对于给定的训练数据集T和超平面$(w,b)$，定义超平面$(w,b)$关于**样本点$(x_i,y_i)$**的函数间隔为$$\\hat \\gamma_i=y_i(w\\cdot x_i+b)$$\n",
    "定义超平面$(w,b)$关于**训练数据集T**的函数间隔为超平面$(w,b)$关于T中所有样本点$(x_i,y_i)$的函数间隔之最小值，即$$\\hat \\gamma=min\\hat \\gamma_i$$函数间隔可以表示分类预测的正确性及确信程度。\n",
    "\n",
    "如果超平面不变，但是成比例改变w和b，例如改为2w和2b，则函数间隔时原来的2倍。这提示我们，需要对法向量加以约束，使得间隔是确定的。这时，函数间隔就变成了**几何间隔**。\n",
    "\n",
    "**（3）几何间隔**\n",
    "\n",
    "对于给定的训练数据集T和超平面$(w,b)$，定义超平面$(w,b)$关于**样本点$(x_i,y_i)$**的几何间隔为$$\\gamma_i=y_i\\frac{w\\cdot x_i+b}{\\parallel w \\parallel}$$\n",
    "定义超平面$(w,b)$关于**训练数据集T**的几何间隔为超平面$(w,b)$关于T中所有样本点$(x_i,y_i)$的几何间隔之最小值，即$$\\gamma=min \\gamma_i$$函数间隔可以表示分类预测的正确性及确信程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学建模\n",
    "求解这个\"决策面\"的过程，就是最优化。一个最优化问题通常有两个基本的因素：\n",
    "\n",
    "1）目标函数，也就是你希望什么东西的什么指标达到最好；\n",
    "\n",
    "2）优化对象，你期望通过改变哪些因素来使你的目标函数达到最优。\n",
    "\n",
    "在线性SVM算法中，目标函数显然就是那个\"分类间隔\"，而优化对象则是决策面。所以要对SVM问题进行数学建模，首先要对上述两个对象（\"分类间隔\"和\"决策面\"）进行数学描述。按照一般的思维习惯，我们先描述决策面。\n",
    "\n",
    "数学建模的时候，先在二维空间建模，然后再推广到多维。\n",
    "\n",
    "### \"决策面\"方程\n",
    "我们都知道二维空间下一条直线的方式如下所示：$$y=ax+b$$做个小小的改变，让原来的x轴变成$x_1$，y轴变成$x_2$，移项后$ax_1-x_2+b=0$，向量化$$ \\left [\\matrix{a & -1} \\right]\\left [\\matrix{x_1\\cr x_2} \\right]+b=0$$进一步向量化$w^Tx+b=0$，向量化后直线的w和b的几何意义是什么呢？![jupyter](./img/SVM1-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "蓝色的线代表向量w，红色的线代表直线y。我们可以看到向量w和直线的关系为**垂直关系**。这说明了向量w也控制这直线的方向，只不过是与这个直线的方向是垂直的。标量b的作用也没有变，依然决定了直线的截距。此时，我们称**w为直线的法向量**。\n",
    "\n",
    "二维空间的直线方程已经推导完成，将其推广到n维空间，就变成了超平面方程。(一个超平面，在二维空间的例子就是一个直线)但是它的公式没变，此时$$w=[w_1,w_2,\\dots,w_n]^T，x=[x_1,x_2,\\dots,x_n]^T$$\n",
    "###  \"分类间隔\"方程\n",
    "\n",
    "现在，我们依然对于一个二维平面的简单例子进行推导。![jupyter](./img/SVM1-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "间隔的大小实际上就是支持向量对应的样本点到决策面的距离的二倍。**点到直线的距离距离公式**如下：$$d=|\\frac{Ax_0+By_0+C}{\\sqrt{A^2+B^2}}|$$公式中的直线方程为$Ax+By+C=0$，点P的坐标为$(x_0,y_0)$。\n",
    "\n",
    "现在，将直线方程扩展到多维，求得我们现在的超平面方程，对公式进行如下变形：$$d=\\frac{|w^Tx+b|}{||w||}$$这个d就是\"分类间隔\"。其中**||w||表示w的二范数**，求所有元素的平方和，然后再开方。\n",
    "\n",
    "我们目的是为了找出一个分类效果好的超平面作为分类器。**分类器的好坏的评定依据是分类间隔W=2d的大小，即分类间隔w越大，我们认为这个超平面的分类效果越好**。此时，求解超平面的问题就变成了求解分类间隔W最大化的为题。W的最大化也就是d最大化的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 约束条件\n",
    "我们已经顺利获得了目标函数的数学形式，但是为了求解w的最大值。我们不得不面对如下问题：\n",
    "\n",
    "1）如何判断超平面是否将样本点正确分类？\n",
    "\n",
    "2)知道要求距离d的最大值，首先需要找到支持向量上的点，怎么在众多的点中选出支持向量上的点呢？\n",
    "\n",
    "上述需要面对的问题就是**约束条件**，也就是说优化的变量d的取值范围受到了限制和约束。事实上约束条件一直是最优化问题里最让人头疼的东西。但既然已经知道了这些约束条件确实存在，就不得不用数学语言对他们进行描述。但SVM算法通过一些巧妙的小技巧，将这些约束条件融合到一个不等式里面。\n",
    "\n",
    "这个**二维平面上有两种点**，分别对它们进行标记：红颜色的圆点标记为+1，规定其为**正样本**；蓝颜色的五角星标记为-1，规定其为**负样本**。\n",
    "\n",
    "对每个样本点$x_i$加上一个类别标签$y_i$：\n",
    "$$ y_i=\\left\\{ \\begin{align} \n",
    "+1 \\mbox{红色点}\\\\\n",
    "-1 \\mbox{蓝色点}\n",
    "\\end{align} \\right.$$\n",
    "如果我们的超平面方程能够完全正确地对上图的样本点进行分类，就会满足下面的方程：\n",
    "$$\\left\\{ \\begin{align} \n",
    "&w^Tx_i+b>0,y_i=1 \\\\\n",
    "&w^Tx_i+b<0,y_i=-1\n",
    "\\end{align} \\right.\n",
    "$$如果我们要求再高一点，假设决策面正好处于间隔区域的中轴线上，并且相应的支持向量对应的样本点到决策面的距离为d，那么公式进一步写成：$$\\left\\{ \\begin{align}\n",
    "&\\frac{w^Tx_i+b}{\\lVert w\\rVert}\\geqslant d,\\forall y_i=1 \\\\\n",
    "&\\frac{w^Tx_i+b}{\\lVert w\\rVert}\\leqslant -d,\\forall y_i=-1\n",
    "\\end{align} \\right.\n",
    "$$上述公式的解释就是，对于所有分类标签为1和-1样本点，它们到直线的距离都大于等于d(支持向量上的样本点到超平面的距离)。公式两边都除以d，就可以得到：\n",
    "$$\\left\\{ \\begin{align}\n",
    "&w_d^Tx_i+\\gamma_d \\geqslant 1,\\forall y_i=1 \\\\\n",
    "&w_d^Tx_i+\\gamma_d \\leqslant -1,\\forall y_i=-1\n",
    "\\end{align} \\right.\n",
    "$$\n",
    "\n",
    "$$w_d=\\frac{w}{\\lVert w\\rVert d},\\gamma_d=\\frac{\\gamma }{\\lVert w\\rVert d}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以上述公式的两个矢量$w_d$和$γ_d$，依然描述一条直线的法向量和截距。**将上述方程变成如下形式**：$$y_i(w^Tx_i+\\gamma)\\geqslant 1,\\forall x_i$$\n",
    "这里的技巧将标签置为1和-1（而不是1和0），方便我们将约束条件变成一个约束方程，从而便于后续计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除\n",
    "$$\\begin{align}\n",
    "    &x +  y = 1\\\\\n",
    "    &2x + y \\neq 1\\\\\n",
    "    &3x +4y \\leq 2\\\\\n",
    "    &4x \\geq y\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{eqnarray*}\n",
    "\\cos 2 \\theta & = & \\cos^2 \\theta - \\sin^2 \\theta\\\\\n",
    "&=& 2\\cos^2 \\theta - 1 \\end{eqnarray*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性SVM优化问题基本描述\n",
    "\n",
    "上面得到了目标函数：$$d=\\frac{|w^Tx+\\gamma|}{\\lVert w \\rVert}$$优化目标是d最大化。\n",
    "\n",
    "我们用支持向量上的样本点求解d的最大化的问题的。那么支持向量上的样本点有什么特点呢？$$|w^Tx_i+\\gamma|=1,\\forall支持向量上的样本点x_i$$将我们的目标函数进一步化简：$$d=\\frac{1}{\\lVert w \\rVert}$$因为，我们只关心支持向量上的点。随后我们求解d的最大化问题变成了||w||的最小化问题。进而||w||的最小化问题等效于\n",
    "$$\\left\\{\\begin{align}\n",
    "&min\\frac{1}{2}{\\lVert w \\rVert}^2\\tag 1\\\\\n",
    "&s.t. \\\\\n",
    "&y_i(w^Tx_i+b)\\geqslant1,i=1,2,\\dots,n \\tag 2\n",
    "\\end{align}\\right.$$\n",
    "这个等式变化是为了最优化的过程中对目标函数求导时比较方便，但这绝对不影响最优化问题最后的求解。\n",
    "\n",
    "这里n是样本点的总个数，缩写s.t.表示\"Subject to\"，是\"服从某某条件\"的意思。上述公式描述的是一个典型的不等式约束条件下的二次型函数优化问题，同时也是支持向量机的基本数学模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求解准备\n",
    "\n",
    "得到支持向量机的基本数学模型，接下来的问题就是求解模型的最优解。在学习求解方法之前，先了解求解方法的前提，就是我们的目标函数必须是**凸函数**。理解凸函数，我们还要先明确另一个概念，**凸集**。在凸几何中，凸集(convex set)是在凸组合下闭合的放射空间的子集。看一幅图可能更容易理解：![jupyter](./img/SVM1-7.png)左右量图都是一个集合。如果集合中任意2个元素连线上的点也在集合中，那么这个集合就是凸集。显然，上图中的左图是一个凸集，上图中的右图是一个非凸集。\n",
    "\n",
    "**凸函数**的定义也是如此，其几何意义表示为函数任意两点连线上的值大于对应自变量处的函数值。若这里凸集C即某个区间L，那么，设函数f为定义在区间L上的函数，若对L上的任意两点x1，x2和任意的实数λ，λ属于(0,1)，总有：$$f(\\lambda x_1+(1-\\lambda)x_2)<=\\lambda f(x_1)+(1-\\lambda)f(x_2)$$对于我们的目标函数：$$d=\\frac{1}{\\lVert w \\rVert}$$很显然，它是一个凸函数。所以，可以使用下面的方法求取最优解。\n",
    "\n",
    "通常我们需要求解的最优化问题有如下几类(a、b、c)："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a）无约束优化问题：$$minf(x)$$\n",
    "b）有等式的优化问题：\n",
    "$$\\left\\{ \\begin{align}\n",
    "&minf(x) \\\\\n",
    "&s.t.\\\\\n",
    "&h_{i(x)}=0,i=1,2,\\cdots,n\n",
    "\\end{align} \\right.\n",
    "$$\n",
    "c）有不等式约束的优化问题:\n",
    "$$\\left\\{ \\begin{align} \n",
    "&minf(x) \\\\\n",
    "&s.t.\\\\\n",
    "&g_{i(x)}\\le 0,i=1,2,\\cdots,n\\\\\n",
    "&h_{i(x)}=0,i=1,2,\\cdots,n\n",
    "\\end{align} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于第(a)类的优化问题，尝试使用的方法就是**费马大定理(Fermat)**，即使用求取函数f(x)的导数，然后令其为零，可以求得候选最优值，再在这些候选值中验证；如果是凸函数，可以保证是最优解。这也就是我们高中经常使用的求函数的极值的方法。\n",
    "\n",
    "对于第(b)类的优化问题，常常使用的方法就是**拉格朗日乘子法（Lagrange Multiplier)**，即把等式约束$h_i(x)$用一个系数与f(x)写为一个式子，称为**拉格朗日函数**，而系数称为**拉格朗日乘子**。通过拉格朗日函数对各个变量求导，令其为零，可以求得候选值集合，然后验证求得最优值。\n",
    "\n",
    "对于第(c)类的优化问题，常常使用的方法就是**KKT条件**。同样地，我们把所有的等式、不等式约束与f(x)写为一个式子，也叫拉格朗日函数，系数也称拉格朗日乘子，通过一些条件，可以求出最优值的必要条件，这个条件称为KKT条件。\n",
    "\n",
    "必要条件和充要条件如果不理解，可以看下面这句话：A的必要条件就是A可以推出的结论，A的充分条件就是可以推出A的前提。\n",
    "\n",
    "了解到这些，现在再看一下我们的最优化问题：$$\\left\\{\\begin{align}\n",
    "&min\\frac{1}{2}{\\lVert w \\rVert}^2\\\\\n",
    "&s.t. \\\\\n",
    "&y_i(w^Tx_i+b)\\geqslant1,i=1,2,\\dots,n\n",
    "\\end{align}\\right.$$\n",
    "这个优化问题属于第(c)类问题。在学习求解最优化问题之前，我们还要学习两个东西：**拉格朗日函数和KKT条件**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拉格朗日函数\n",
    "\n",
    "首先，我们先要从宏观的视野上了解一下**拉格朗日对偶问题**出现的原因和背景。\n",
    "\n",
    "我们知道我们要求解的是最小化问题，所以一个直观的想法是如果我能够构造一个函数，使得该函数在可行解区域内与原目标函数完全一致，而在可行解区域外的数值非常大，甚至是无穷大，那么这个没有约束条件的新目标函数的优化问题就与原来有约束条件的原始目标函数的优化问题是等价的问题。这就是使用拉格朗日方程的目的，它将约束条件放到目标函数中，从而**将有约束优化问题转换为无约束优化问题**。\n",
    "\n",
    "随后，人们又发现，使用拉格朗日获得的函数，使用求导的方法求解依然困难。进而，需要对问题再进行一次转换，即使用一个数学技巧：**拉格朗日对偶**。\n",
    "\n",
    "所以，显而易见的是，我们在拉格朗日优化我们的问题这个道路上，需要进行下面二个步骤：\n",
    "\n",
    "1）将有约束的原始目标函数转换为无约束的新构造的拉格朗日目标函数\n",
    "\n",
    "2）使用拉格朗日对偶性，将不易求解的优化问题转化为易求解的优化\n",
    "\n",
    "下面，进行第一步：**将有约束的原始目标函数转换为无约束的新构造的拉格朗日目标函数**\n",
    "\n",
    "公式变形如下：$$L(w,b,a)=\\frac{1}{2}\\parallel w \\parallel^2-\\sum_{i=1}^na_i(y_i(w^Tx_i+b)-1)$$\n",
    "其中$a_i\\geqslant 0$是拉格朗日乘子，是我们构造新目标函数时引入的系数变量(我们自己设置)。现在令：$$\\theta(w)=max_{a_i\\geqslant 0}L(w,b,a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当样本点不满足约束条件时，即在可行解区域外：$$y_i(w^Tx_i+b)< 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时，我们将$a_i$设置为正无穷，此时θ(w)显然也是正无穷。\n",
    "\n",
    "当样本点满足约束条件时，即在可行解区域内：$$y_i(w^Tx_i+b)\\geq 1$$此时，显然θ(w)为原目标函数本身。我们将上述两种情况结合一下，就得到了**新的目标函数**：\n",
    "$$\\theta(w)=\\left\\{ \\begin{align}\n",
    "&\\frac{1}{2}\\parallel w \\parallel^2 ,x\\in 可行区 \\\\\n",
    "&+\\infty ,x\\in 非可行区\n",
    "\\end{align} \\right.\n",
    "$$\n",
    "此时，再看我们的初衷，就是为了建立一个在可行解区域内与原目标函数相同，在可行解区域外函数值趋近于无穷大的新函数，现在我们做到了。\n",
    "\n",
    "现在，我们的问题变成了求新目标函数的最小值，即：$$min_{w,b}\\theta (w)=min_{w,b}max_{a_i\\geqslant 0}L(w,b,a)=p^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用p*表示这个问题的最优值，且和最初的问题是等价的。\n",
    "\n",
    "接下来，我们进行第二步：**将不易求解的优化问题转化为易求解的优化**\n",
    "\n",
    "看一下新目标函数，先求最大值，再求最小值。这样的话，我们首先就要面对带有需要求解的参数w和b的方程，而$a_i$是不等式约束，这个求解过程不好做。所以，我们需要使用拉格朗日函数对偶性，将最小和最大的位置交换一下，这样就变成了：$$max_{a_i\\geqslant 0}min_{w,b}L(w,b,a)=p^*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交换以后的新问题是原始问题的**对偶问题**，这个新问题的最优值用d*来表示。而且d*<=p*。我们关心的是d=p的时候，这才是我们要的解。需要什么条件才能让d=p呢？\n",
    "\n",
    "1)首先必须满足这个优化问题是凸优化问题。\n",
    "\n",
    "2)其次，需要满足KKT条件。\n",
    "\n",
    "凸优化问题的定义是：求取最小值的目标函数为凸函数的一类优化问题。目标函数是凸函数我们已经知道，这个优化问题又是求最小值。所以我们的最优化问题就是凸优化问题。\n",
    "\n",
    "接下里，就是探讨是否满足KKT条件了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KKT条件\n",
    "\n",
    "我们已经使用拉格朗日函数对我们的目标函数进行了处理，生成了一个新的目标函数。通过一些条件，可以求出最优值的必要条件，这个条件就是接下来要说的KKT条件。一个最优化模型能够表示成下列标准形式：$$\\theta(w)=\\left\\{ \\begin{align}\n",
    "&min f(x) \\\\\n",
    "&s.t.\\\\\n",
    "&h_j(x)=0,j=1,2,\\cdots,p\\\\\n",
    "&g_k(x)\\leqslant 0,k=1,2,\\cdots,q\\\\\n",
    "&x\\in X\\subset R^n\n",
    "\\end{align} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KKT条件的全称是Karush-Kuhn-Tucker条件，**KKT条件是说最优值条件必须满足以下条件**：\n",
    "\n",
    "条件一：经过拉格朗日函数处理之后的新目标函数$L(w,b,α)$对x求导为零：\n",
    "\n",
    "条件二：h(x) = 0；\n",
    "\n",
    "条件三：α*g(x) = 0；\n",
    "\n",
    "现在，凸优化问题和KKT都满足了，问题转换成了对偶问题。而求解这个对偶学习问题，可以分为三个步骤：首先要让L(w,b,α)关于w和b最小化，然后求对α的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。现在，我们继续推导。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对偶问题求解\n",
    "上述已经求得拉格朗日函数$$L(w,b,a)=\\frac{1}{2}\\parallel w \\parallel^2-\\sum_{i=1}^na_i(y_i(w^Tx_i+b)-1)$$\n",
    "根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：$$max_{a_i\\geqslant 0}min_{w,b}L(w,b,a)$$\n",
    "所以，为了得到对偶问题的求解，需要先求$L(w,b,a)$对$w,b$的极小问题，再求对$a$的极大问题。\n",
    "\n",
    "第一步：求$$min_{w,b}L(w,b,a)$$\n",
    "将拉格朗日函数$L(w,b,a)$分别对$w,b$求偏导，并令其为0。得到\n",
    "$$w=\\sum_i^na_iy_ix_i$$$$\\sum_i^na_iy_i=0$$\n",
    "将结果带入拉格朗日函数$L(w,b,a)$，并利用上面结果，得到\n",
    "$$\\begin{eqnarray*}\n",
    "L(w,b,a)&=&\\frac{1}{2}\\parallel w \\parallel^2-\\sum_{i=1}^na_i(y_i(w^Tx_i+b)-1)\\\\\n",
    "&=&\\frac{1}{2}\\parallel w \\parallel^2-\\sum_{i=1}^na_i(y_i(w^Tx_i+b))+\\sum_{i=1}^na_i)\\\\\n",
    "&=&\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)-\\sum_i^na_iy_i((\\sum_j^na_jy_jx_j)\\cdot x_i+b)+\\sum_i^na_i\\\\\n",
    "&=&-\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)+\\sum_i^na_i\\\\\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "第二步：求$min_{w,b}L(w,b,a)$对$a$的极大，即是对偶问题\n",
    "$$\\begin{align}\n",
    "&max_a-\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)+\\sum_i^na_i \\tag 4\\\\\n",
    "&s.t.\\\\\n",
    "&\\sum_i^na_iy_i=0 \\tag 5\\\\\n",
    "&a_i\\geqslant 0,i=1,2,\\cdots,n \\tag 6\n",
    "\\end{align}$$\n",
    "\n",
    "这意味着，原始优化问题（1）、（2）可以转化为求解对偶问题（4）、（5）、（6）,并且存在解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对线性可分数据集，假设对偶最有问题（4）、（5）、（6）对$a$的解为$a^*=(a_1^*,a_2^*,\\cdots,a_n^*)$，则可由$a^*$求得原始问题的解$(w^*,b^*)$。\n",
    "$$\\begin{align}\n",
    "&w^*=\\sum_i^na_i^*y_ix_i \\tag 7\\\\\n",
    "&b^*=y_i-\\sum_i^na_i^*y_i(x_i\\cdot x_j) \\tag 8\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**支持向量定义**，考虑原始优化问题（1）（2），及对偶优化问题（3）（4）（5），将训练数据集中对应于$a^*$的样本点$(x_i,y_j)$的实例$x_i\\in R^n$称为**支持向量**。\n",
    "\n",
    "根据这一定义，支持向量一定在间隔边界上，由KKT条件可知，$$a_i^*(y_i(w^*\\cdot x_i+b^*)-1)=0,i=1,2,\\cdots,n$$对应于$a_i^*>0$的$x_i$，有$$y_i(w^*\\cdot x_i+b^*)-1=0$$或者$$w^*\\cdot x_i+b^*=\\pm$$即$x_i$一定在间隔边界上。这里的支持向量的定义于前面给出的支持向量的定义是一致的。\n",
    "\n",
    "**例子：**已知训练集T，正例点是$x_1=(3,3)^T,x_2=(4,3)^T$，负例点是$x_3=(1,1)^T$。试求线性可分支持向量机。\n",
    "\n",
    "根据所给数据，对偶问题是(公式4)：\n",
    "$$\\begin{align}\n",
    "&min_a-\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)-\\sum_i^na_i\\\\\n",
    "&=\\frac{1}{2}(18a_1^2+25a_2^2+2a_3^2+42a_1a_2-12a_1a_3-14a_2a_3)-a_1-a_2-a_3\\\\\n",
    "&s.t. \\\\\n",
    "&a_1+a_2-a_3=0,a_i\\geqslant 0,i=1,2,3\\end{align}$$\n",
    "将$a_3=a_1+a_2$带入目标函数并记为$$s(a_1,a_2)=4a_1^2+6.5a_2^2+10a_1a_2-2a_1-2a_2$$\n",
    "分别求偏导并令其为0，得极值点$(\\frac{3}{2},-1)^T$，但该点不满足约束条件$a_i\\geqslant 0$，所以最小点应在边界上达到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当$a_1=0$,最小值是$s(0,\\frac{2}{13})=-\\frac{2}{13}$；当$a_2=0$，最小值$s(\\frac{1}{4},0)=-\\frac{1}{4}$。于是$s(a_1,a_2)$在$a_1=\\frac{1}{4},a_2=0$达到最小，此时，$a_3=\\frac{1}{4}$。\n",
    "\n",
    "这样，$a^*=(\\frac{1}{4},0,\\frac{1}{4})$对应的实例点$x_1,x_3$是支持向量，根据（7）（8）得到$$w_1^*=w_2^*=\\frac{1}{2},b^*=-2$$\n",
    "分离超平面为$$\\frac{1}{2}x^{(1)}+\\frac{1}{2}x^{(2)}-2=0$$\n",
    "二分类决策函数为$$f(x)=sign\\left(\\frac{1}{2}x^{(1)}+\\frac{1}{2}x^{(2)}-2\\right)$$\n",
    "\n",
    "这个例子是线性可分的，算法是完美的。但是线性可分是理想情形，样本常有噪声或特异点。此时有更一般的学习算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有更高效的优化算法，即**序列最小优化（SMO）算法**。我们通过这个优化算法能得到α，再根据α，我们就可以求解出w和b，进而求得我们最初的目的：找到超平面，即\"决策平面\"。\n",
    "\n",
    "总结一句话：我们为啥使出吃奶的劲儿进行推导？因为我们要将最初的原始问题，转换到可以使用SMO算法求解的问题，这是一种最流行的求解方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMO算法\n",
    "现在，我们已经得到了可以用SMO算法求解的目标函数，但是对于怎么编程实现SMO算法还是感觉无从下手。那么现在就聊聊如何使用SMO算法进行求解。\n",
    "### Platt的SMO算法\n",
    "1996年，John Platt发布了一个称为SMO的强大算法，用于训练SVM。SMO表示序列最小化(Sequential Minimal Optimizaion)。Platt的SMO算法是**将大优化问题分解为多个小优化问题来求解的**。这些小优化问题往往很容易求解，并且对它们进行顺序求解的结果与将它们作为整体来求解的结果完全一致的。在结果完全相同的同时，SMO算法的求解时间短很多。\n",
    "\n",
    "SMO算法的目标是求出一系列a和b，一旦求出了这些a，就很容易计算出权重向量w并得到分隔超平面。\n",
    "\n",
    "SMO算法的**工作原理**是：每次循环中选择两个a进行优化处理。一旦找到了一对合适的a，那么就增大其中一个同时减小另一个。这里所谓的\"合适\"就是指两个a必须**符合以下两个条件**，条件之一就是两个a必须要在间隔边界之外，而且第二个条件则是这两个a还没有进行过区间化处理或者不在边界上。\n",
    "### SMO算法的解法\n",
    "先来定义特征到结果的输出函数为：\n",
    "$$u=w^Tx+b$$\n",
    "我们的原始是\n",
    "$$\\begin{align}\n",
    "&min\\frac{1}{2}{\\lVert w \\rVert}^2\\\\\n",
    "&s.t. \\\\\n",
    "&y_i(w^Tx_i+b)\\geqslant1,i=1,2,\\dots,n \\tag 2\n",
    "\\end{align}$$\n",
    "求导得到了：\n",
    "$$w=\\sum_i^na_iy_ix_i$$\n",
    "带入到函数$u$:\n",
    "$$u=\\sum_i^na_iy_ix_i^Tx_i+b$$\n",
    "拉格朗日对偶后，得到最终的目标函数：\n",
    "$$\\begin{align}\n",
    "&max_a-\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)+\\sum_i^na_i\\\\\n",
    "&s.t.\\\\\n",
    "&\\sum_i^na_iy_i=0,a_i\\geqslant 0,i=1,2,\\cdots,n\n",
    "\\end{align}$$\n",
    "在目标函数前加一个负号，转化为最小问题：\n",
    "$$\\begin{align}\n",
    "&min_a\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)-\\sum_i^na_i\\\\\n",
    "&s.t.\\\\\n",
    "&\\sum_i^na_iy_i=0\\\\\n",
    "&a_i\\geqslant 0,i=1,2,\\cdots,n\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于上述问题，存在一个假设：**数据线性可分**。但是数据几乎都不“干净”，导致线性不可分。**线性不可分意味着某些样本点$(x_i,y_i)$不能满足函数间隔大于等于1的约束条件（公式2）。**为了解决这个问题，可以对每个样本点引进一个松弛变量$\\xi_i\\geqslant 0$，使得函数间隔加上松弛变量大于等于1。这样，约束条件就变为$$y_i(w\\cdot x_i+b)\\geqslant 1-\\xi_i$$同时，对每个松弛变量$\\xi_i$，支付一个代价$C$，目标函数（1）就变成了$$\\frac{1}{2}\\parallel w \\parallel^2+C\\sum_{i=1}^n\\xi_i\\tag 9$$\n",
    "这里，$C>0$称为惩罚参数，一般由应用问题确定，值大时对误分类的惩罚增大，$C$值小时对误分类的惩罚减小。这个目标函数（9）包含两层含义：使$\\frac{1}{2}\\parallel w \\parallel^2$尽量小即间隔尽量大，同时使得误分类点的个数尽量少，$C$是二者的调和系数。\n",
    "\n",
    "**有了这样的思路，对线性不可分问题，可以和线性可分一样来考虑。**线性不可分的线性支持向量机的学习问题就是如下的表达：\n",
    "$$\\begin{align}\n",
    "&\\frac{1}{2}\\parallel w \\parallel^2+C\\sum_{i=1}^n\\xi_i \\tag {10}\\\\\n",
    "&s.t.\\\\\n",
    "&y_i(w\\cdot x_i+b)\\geqslant 1-\\xi_i \\tag{11}\\\\\n",
    "&\\xi_i\\geqslant 0,i=1,2,\\cdot,n \\tag{12}\n",
    "\\end{align}$$\n",
    "\n",
    "原始问题（10）-（12）的对偶问题是\n",
    "$$\\begin{align}\n",
    "&min_a\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)-\\sum_i^na_i\\\\\n",
    "&s.t.\\\\\n",
    "&\\sum_i^na_iy_i=0\\\\\n",
    "&C\\geqslant a_i\\geqslant 0,i=1,2,\\cdots,n\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始问题（10）-（12）的拉格朗日函数为$$L(w,b,\\xi,a,u)=\\frac{1}{2}\\parallel w \\parallel^2+C\\sum_i^n\\xi_i-\\sum_{i=1}^na_i(y_i(wx_i+b)-1+\\xi_i)-\\sum_i^nu_i\\xi_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，$a_i\\geqslant 0,u_i\\geqslant 0$。\n",
    "对偶问题拉格朗日函数的一个极大极小问题，首先求$L(w,b,\\xi,a,u)$对$w,b,\\xi$de **极小值**，由\n",
    "$$\\begin{align}\n",
    "&\\nabla_wL(w,b,\\xi,a,u)=w-\\sum_ia_iy_ix_i=0\\\\\n",
    "&\\nabla_bL(w,b,\\xi,a,u)=-\\sum_ia_iy_i=0\\\\\n",
    "&\\nabla_{\\xi_i}L(w,b,\\xi,a,u)=C-a_i-u_i=0\n",
    "\\end{align}$$得到\n",
    "$$\\begin{align}\n",
    "&w=\\sum_ia_iy_ix_i=0\\tag{13}\\\\\n",
    "&\\sum_ia_iy_i=0\\tag{14}\\\\\n",
    "&C-a_i-u_i=0\\tag{15}\n",
    "\\end{align}$$将（13）-（15）带入$L(w,b,\\xi,a,u)$得到\n",
    "$$min_{w,b,\\xi}L(w,b,\\xi,a,u)=-\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)+\\sum_i^na_i$$\n",
    "再对上式$min_{w,b,\\xi}L(w,b,\\xi,a,u)$求$a$的极大值，即得到对偶问题：\n",
    "$$\\begin{align}\n",
    "&min_a-\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)+\\sum_i^na_i\\\\\n",
    "&s.t.\\\\\n",
    "&\\sum_ia_iy_i=0\\\\\n",
    "&C-a_i-u_i=0\\\\\n",
    "&a_i\\geqslant 0\\\\\n",
    "&u_i\\geqslant 0,i=1,2,\\cdots,n\n",
    "\\end{align}$$\n",
    "消去$u_i$，只留下$a_i$，得到本小节前面提到的对偶问题：\n",
    "$$\\begin{align}\n",
    "&min_a\\frac{1}{2}\\sum_i^n\\sum_j^na_ia_jy_iy_j(x_i\\cdot x_j)-\\sum_i^na_i\\\\\n",
    "&s.t.\\\\\n",
    "&\\sum_i^na_iy_i=0\\\\\n",
    "&C\\geqslant a_i\\geqslant 0,i=1,2,\\cdots,n\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【定理】**设$a^*=(a_1^*,a_2^*,\\cdots,a_N^*)$是对偶问题的一个解，若存在$a^*$的一个分量$a_j^*，0<a_j^*<C$，则原始问题的解为\n",
    "$$w^*=\\sum_ia_i^*y_ix_i$$$$b^*=y_i-\\sum_iy_ia_i^*(x_i\\cdot x_j)$$证明略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程求解线性SVM\n",
    "已经梳理完了SMO算法实现步骤，接下来按照这个思路编写代码，进行实战练习。\n",
    "### 可视化数据集\n",
    "我们先使用简单的数据集进行测试，先看看数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:读取数据 \\nParameters:\\n    fileName - 文件名\\nReturns:\\n    dataMat - 数据矩阵\\n    labelMat - 数据标签\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:数据可视化 \\nParameters:\\n    dataMat - 数据矩阵\\n    labelMat - 数据标签\\nReturns:\\n    无\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding:UTF-8 -*-\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#在下面添加此代码以显示单元格中的所有输出\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "\n",
    "\"\"\"\n",
    "函数说明:读取数据 \n",
    "Parameters:\n",
    "    fileName - 文件名\n",
    "Returns:\n",
    "    dataMat - 数据矩阵\n",
    "    labelMat - 数据标签\n",
    "\"\"\"\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():                                     #逐行读取，滤除空格等\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])      #添加数据\n",
    "        labelMat.append(float(lineArr[2]))                          #添加标签\n",
    "    return dataMat,labelMat\n",
    " \n",
    "\"\"\"\n",
    "函数说明:数据可视化 \n",
    "Parameters:\n",
    "    dataMat - 数据矩阵\n",
    "    labelMat - 数据标签\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def showDataSet(dataMat, labelMat):\n",
    "    data_plus = []                                  #正样本\n",
    "    data_minus = []                                 #负样本\n",
    "    for i in range(len(dataMat)):\n",
    "        if labelMat[i] > 0:\n",
    "            data_plus.append(dataMat[i])\n",
    "        else:\n",
    "            data_minus.append(dataMat[i])\n",
    "    data_plus_np = np.array(data_plus)              #转换为numpy矩阵\n",
    "    data_minus_np = np.array(data_minus)            #转换为numpy矩阵\n",
    "    plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1])   #正样本散点图\n",
    "    plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1]) #负样本散点图\n",
    "    plt.show()\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    dataMat, labelMat = loadDataSet('./DataSet/SVMtestSet2.txt')\n",
    "    showDataSet(dataMat, labelMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是我们使用的二维数据集，显然线性可分。现在我们使用简化版的SMO算法进行求解。\n",
    "### 简化版SMO算法\n",
    "按照上述已经推导的步骤编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:读取数据 \\nParameters:\\n    fileName - 文件名\\nReturns:\\n    dataMat - 数据矩阵\\n    labelMat - 数据标签\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:随机选择alpha\\n \\nParameters:\\n    i - alpha\\n    m - alpha参数个数\\nReturns:\\n    j -\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:修剪alpha\\n \\nParameters:\\n    aj - alpha值\\n    H - alpha上限\\n    L - alpha下限\\nReturns:\\n    aj - alpah值\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:简化版SMO算法\\n \\nParameters:\\n    dataMatIn - 数据矩阵\\n    classLabels - 数据标签\\n    C - 惩罚参数\\n    toler - 松弛变量\\n    maxIter - 最大迭代次数\\nReturns:\\n    无\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:分类结果可视化\\n \\nParameters:\\n    dataMat - 数据矩阵\\n    w - 直线法向量\\n    b - 直线解决\\nReturns:\\n    无\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n函数说明:计算w\\n \\nParameters:\\n    dataMat - 数据矩阵\\n    labelMat - 数据标签\\n    alphas - alphas值\\nReturns:\\n    无\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:4, alpha优化次数:1\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:10, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:17, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:25, alpha优化次数:4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:36, alpha优化次数:5\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:46, alpha优化次数:6\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:55, alpha优化次数:7\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:60, alpha优化次数:8\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:96, alpha优化次数:9\n",
      "迭代次数: 0\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第0次迭代 样本:17, alpha优化次数:1\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:52, alpha优化次数:1\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:30, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:60, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:4, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "第0次迭代 样本:39, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:69, alpha优化次数:3\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第0次迭代 样本:25, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:29, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:55, alpha优化次数:3\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:4, alpha优化次数:1\n",
      "第0次迭代 样本:7, alpha优化次数:2\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "L==H\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第1次迭代 样本:27, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:39, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第1次迭代 样本:55, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:52, alpha优化次数:2\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第1次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:27, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:62, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "第0次迭代 样本:0, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:29, alpha优化次数:1\n",
      "第0次迭代 样本:30, alpha优化次数:2\n",
      "第0次迭代 样本:46, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第4次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "第3次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第3次迭代 样本:29, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:69, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:10, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:52, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第0次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:54, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:69, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:54, alpha优化次数:2\n",
      "第0次迭代 样本:55, alpha优化次数:3\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:69, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:17, alpha优化次数:1\n",
      "第0次迭代 样本:29, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:55, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "第2次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:29, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第3次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "第7次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第2次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第4次迭代 样本:30, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "第3次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "第2次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:55, alpha优化次数:2\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:69, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "第7次迭代 样本:8, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第7次迭代 样本:55, alpha优化次数:2\n",
      "第7次迭代 样本:69, alpha优化次数:3\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "第6次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第7次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "第5次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "第2次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第12次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第2次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "第3次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "第12次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "第1次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第4次迭代 样本:55, alpha优化次数:1\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "第7次迭代 样本:52, alpha优化次数:1\n",
      "第7次迭代 样本:55, alpha优化次数:2\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "第0次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "L==H\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 15\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 16\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第16次迭代 样本:52, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第6次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第1次迭代 样本:23, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第11次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 15\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 16\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 17\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 18\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 19\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 20\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 21\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 22\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 23\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 24\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 25\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 26\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 27\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 28\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 29\n",
      "第29次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "第4次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "第10次迭代 样本:17, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "第11次迭代 样本:55, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "第13次迭代 样本:54, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 15\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 16\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 17\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 18\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 19\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 20\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 21\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 22\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 23\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 24\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 25\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 26\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 27\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 28\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 29\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 30\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 31\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 32\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 33\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 34\n",
      "alpha_j变化太小\n",
      "第34次迭代 样本:29, alpha优化次数:1\n",
      "alpha_j变化太小\n",
      "迭代次数: 0\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 1\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 2\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 3\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 4\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 5\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 6\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 7\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 8\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 9\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 10\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 11\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 12\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 13\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 14\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 15\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 16\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 17\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 18\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 19\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 20\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 21\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 22\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 23\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 24\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 25\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 26\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 27\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 28\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 29\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 30\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 31\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 32\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 33\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 34\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 35\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 36\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 37\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 38\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 39\n",
      "alpha_j变化太小\n",
      "alpha_j变化太小\n",
      "迭代次数: 40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding:UTF-8 -*-\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import types\n",
    " \n",
    "\"\"\"\n",
    "函数说明:读取数据 \n",
    "Parameters:\n",
    "    fileName - 文件名\n",
    "Returns:\n",
    "    dataMat - 数据矩阵\n",
    "    labelMat - 数据标签\n",
    "\"\"\"\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():                                     #逐行读取，滤除空格等\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])      #添加数据\n",
    "        labelMat.append(float(lineArr[2]))                          #添加标签\n",
    "    return dataMat,labelMat\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:随机选择alpha\n",
    " \n",
    "Parameters:\n",
    "    i - alpha\n",
    "    m - alpha参数个数\n",
    "Returns:\n",
    "    j -\n",
    "\"\"\"\n",
    "def selectJrand(i, m):\n",
    "    j = i                                 #选择一个不等于i的j\n",
    "    while (j == i):\n",
    "        j = int(random.uniform(0, m))\n",
    "    return j\n",
    " \n",
    "\"\"\"\n",
    "函数说明:修剪alpha\n",
    " \n",
    "Parameters:\n",
    "    aj - alpha值\n",
    "    H - alpha上限\n",
    "    L - alpha下限\n",
    "Returns:\n",
    "    aj - alpah值\n",
    "\"\"\"\n",
    "def clipAlpha(aj,H,L):\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n",
    " \n",
    "\"\"\"\n",
    "函数说明:简化版SMO算法\n",
    " \n",
    "Parameters:\n",
    "    dataMatIn - 数据矩阵\n",
    "    classLabels - 数据标签\n",
    "    C - 惩罚参数\n",
    "    toler - 松弛变量\n",
    "    maxIter - 最大迭代次数\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    #转换为numpy的mat存储\n",
    "    dataMatrix = np.mat(dataMatIn); labelMat = np.mat(classLabels).transpose()\n",
    "    #初始化b参数，统计dataMatrix的维度\n",
    "    b = 0; m,n = np.shape(dataMatrix)\n",
    "    #初始化alpha参数，设为0\n",
    "    alphas = np.mat(np.zeros((m,1)))\n",
    "    #初始化迭代次数\n",
    "    iter_num = 0\n",
    "    #最多迭代matIter次\n",
    "    while (iter_num < maxIter):\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            #步骤1：计算误差Ei\n",
    "            fXi = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b\n",
    "            Ei = fXi - float(labelMat[i])\n",
    "            #优化alpha，更设定一定的容错率。\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "                #随机选择另一个与alpha_i成对优化的alpha_j\n",
    "                j = selectJrand(i,m)\n",
    "                #步骤1：计算误差Ej\n",
    "                fXj = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                #保存更新前的aplpha值，使用深拷贝\n",
    "                alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy();\n",
    "                #步骤2：计算上下界L和H\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H: print(\"L==H\"); continue\n",
    "                #步骤3：计算eta\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if eta >= 0: print(\"eta>=0\"); continue\n",
    "                #步骤4：更新alpha_j\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                #步骤5：修剪alpha_j\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): print(\"alpha_j变化太小\"); continue\n",
    "                #步骤6：更新alpha_i\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])\n",
    "                #步骤7：更新b_1和b_2\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                #步骤8：根据b_1和b_2更新b\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                #统计优化次数\n",
    "                alphaPairsChanged += 1\n",
    "                #打印统计信息\n",
    "                print(\"第%d次迭代 样本:%d, alpha优化次数:%d\" % (iter_num,i,alphaPairsChanged))\n",
    "        #更新迭代次数\n",
    "        if (alphaPairsChanged == 0): iter_num += 1\n",
    "        else: iter_num = 0\n",
    "        print(\"迭代次数: %d\" % iter_num)\n",
    "    return b,alphas\n",
    " \n",
    "\"\"\"\n",
    "函数说明:分类结果可视化\n",
    " \n",
    "Parameters:\n",
    "    dataMat - 数据矩阵\n",
    "    w - 直线法向量\n",
    "    b - 直线解决\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def showClassifer(dataMat, w, b):\n",
    "    #绘制样本点\n",
    "    data_plus = []                                  #正样本\n",
    "    data_minus = []                                 #负样本\n",
    "    for i in range(len(dataMat)):\n",
    "        if labelMat[i] > 0:\n",
    "            data_plus.append(dataMat[i])\n",
    "        else:\n",
    "            data_minus.append(dataMat[i])\n",
    "    data_plus_np = np.array(data_plus)              #转换为numpy矩阵\n",
    "    data_minus_np = np.array(data_minus)            #转换为numpy矩阵\n",
    "    plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1], s=30, alpha=0.7)   #正样本散点图\n",
    "    plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1], s=30, alpha=0.7) #负样本散点图\n",
    "    #绘制直线\n",
    "    x1 = max(dataMat)[0]\n",
    "    x2 = min(dataMat)[0]\n",
    "    a1, a2 = w\n",
    "    b = float(b)\n",
    "    a1 = float(a1[0])\n",
    "    a2 = float(a2[0])\n",
    "    y1, y2 = (-b- a1*x1)/a2, (-b - a1*x2)/a2\n",
    "    plt.plot([x1, x2], [y1, y2])\n",
    "    #找出支持向量点\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        if alpha > 0:\n",
    "            x, y = dataMat[i]\n",
    "            plt.scatter([x], [y], s=150, c='none', alpha=0.7, linewidth=1.5, edgecolor='red')\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:计算w\n",
    " \n",
    "Parameters:\n",
    "    dataMat - 数据矩阵\n",
    "    labelMat - 数据标签\n",
    "    alphas - alphas值\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def get_w(dataMat, labelMat, alphas):\n",
    "    alphas, dataMat, labelMat = np.array(alphas), np.array(dataMat), np.array(labelMat)\n",
    "    w = np.dot((np.tile(labelMat.reshape(1, -1).T, (1, 2)) * dataMat).T, alphas)\n",
    "    return w.tolist()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    dataMat, labelMat = loadDataSet('./DataSet/SVMtestSet2.txt')\n",
    "    b,alphas = smoSimple(dataMat, labelMat, 0.6, 0.001, 40)\n",
    "    w = get_w(dataMat, labelMat, alphas)\n",
    "    showClassifer(dataMat, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，中间的蓝线为求出来的分类器，用红圈圈出的点为支持向量点。\n",
    "# 总结\n",
    "本文主要进行了线性SVM的推导，并通过编程实现一个简化版SMO算法；\n",
    "本文的简化版SMO算法在选取α的时候，没有选择启发式的选择方法，并且两个乘子的计算没有进行优化，所以算法比较耗时，下一篇文章会讲解相应的优化方法；\n",
    "本文讨论的是线性SVM，没有使用核函数，下一篇文章将会讲解如何应用核函数，将SVM应用于非线性数据集；\n",
    "如有问题，请留言。如有错误，还望指正，谢谢！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
