{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "\n",
    "    https://blog.csdn.net/com_stu_zhang/article/details/6987632\n",
    "    https://www.cnblogs.com/hugechuanqi/p/9697145.html\n",
    "\n",
    "KDD是数据挖掘与知识发现（Data Mining and Knowledge Discovery）的简称，KDD CUP是由ACM（Association for Computing Machiner）的SIGKDD（Special Interest Group on Knowledge Discovery and Data Mining）组织的年度竞赛。**KDD CUP 99 数据集**就是KDD竞赛在1999年举行时采用的数据集。官网下载地址是：http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html。\n",
    "\n",
    "下载的文件信息如下：\n",
    "    \n",
    "    kddcup.names：A list of features. \n",
    "    kddcup.data.gz：The full data set (18M; 743M Uncompressed) \n",
    "    **kddcup.data_10_percent.gz：A 10% subset. (2.1M; 75M Uncompressed) **\n",
    "    kddcup.newtestdata_10_percent_unlabeled.gz：(1.4M; 45M Uncompressed) \n",
    "    kddcup.testdata.unlabeled.gz：(11.2M; 430M Uncompressed) \n",
    "    **kddcup.testdata.unlabeled_10_percent.gz：(1.4M;45M Uncompressed) **\n",
    "    corrected.gz：Test data with corrected labels. \n",
    "    training_attack_types：A list of intrusion types. \n",
    "    typo-correction.txt：A brief note on a typo in the data set that has been corrected (6/26/07) \n",
    "\n",
    "1998年美国国防部高级规划署（DARPA）在MIT林肯实验室进行了一项**入侵检测评估**项目。林肯实验室建立了模拟美国空军局域网的一个网络环境，收集了9周时间的 TCPdump网络连接和系统审计数据，仿真各种用户类型、各种不同的网络流量和攻击手段，使它就像一个真实的网络环境，此时收集的数据称为**KDD98数据集**。这些TCPdump采集的原始数据被分为两个部分：7周时间的具有标识的**训练数据**，大概包含5,000,000多个网络连接记录，2周时间的未加标识的**测试数据**，大概包含2,000,000个网络连接记录。测试数据和训练数据有着不同的概率分布, 测试数据包含了一些未出现在训练数据中的攻击类型, 这使得入侵检测更具有现实性。\n",
    "\n",
    "一个网络连接定义为在某个时间内从开始到结束的TCP数据包序列，并且在这段时间内，数据在预定义的协议下（如TCP、UDP）从源IP地址到目的IP地址的传递。每个网络连接被标记为正常（normal）或异常（attack），异常类型被细分为4大类共39种攻击类型，其中22种攻击类型出现在训练集中，另有17种未知攻击类型出现在测试集中。\n",
    "\n",
    "4种异常类型分别是：\n",
    "    \n",
    "    DOS, denial-of-service. 拒绝服务攻击，例如ping-of-death, syn flood, smurf等；\n",
    "    R2L, unauthorized access from a remote machine to a local machine. 来自远程主机的未授权访问，例如guessing password；\n",
    "    U2R, unauthorized access to local superuser privileges by a local unpivileged user. 未授权的本地超级用户特权访问，例如buffer overflow attacks；\n",
    "    PROBING, surveillance and probing, 端口监视或扫描，例如port-scan, ping-sweep等。\n",
    "\n",
    "随后，来自哥伦比亚大学的Sal Stolfo 教授和来自北卡罗莱纳州立大学的 Wenke Lee 教授采用数据挖掘等技术对以上的数据集进行特征分析和数据预处理，形成了一个新的数据集。该数据集用于1999年举行的KDD CUP竞赛中，成为著名的**KDD CUP 99**数据集，有时简称**KDD99数据集**。虽然年代有些久远，但KDD CUP99数据集仍然是网络入侵检测领域的事实Benckmark，为基于计算智能的网络入侵检测研究奠定基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD99入侵检测实验数据的标识类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 标识类型 | 含义 | 具体分类标识 |\n",
    "| --- | --- | --- |\n",
    "| Normal | 正常记录 |normal |\n",
    "| DOS | 拒绝服务攻击 | back, land, neptune, pod, smurf, teardrop |\n",
    "|Probing|监视和其他探测活动|ipsweep, nmap, portsweep,satan|\n",
    "|R2L|来自远程机器的非法访问|ftp_write, guess_passwd, imap, multihop, phf, spy, warezclient, warezmaster|\n",
    "|U2R|普通用户对本地超级用户特权的非法访问|buffer_overflow, loadmodule, perl, rootkit|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标识类型列用来表示该条连接记录是正常的，或是某个具体的攻击类型，正常连接标识为Normal，只有1种，攻击标识分为4大类共有22种。\n",
    "\n",
    "    DOS：有6种，back,land,neptune,pod,smurf,teardropl\n",
    "    Probing：有4种，ipsweep,nmap,portsweep,satan;\n",
    "    R2L：有8种，ftp_wrute,guess_passwd,imap,multipod,phf,spy,warezclient,waremaster;\n",
    "    U2R：有4种，buffer_overflow,loadmodule,perl,rootkit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 连接的数据特征属性\n",
    "\n",
    "KDD99数据集中每个连接用41个特征来描述，9个特征属性为离散型，其他均为连续型。\n",
    "\n",
    "    duration: continuous.\n",
    "    protocol_type: symbolic.\n",
    "    service: symbolic.\n",
    "    flag: symbolic.\n",
    "    src_bytes: continuous.\n",
    "    dst_bytes: continuous.\n",
    "    land: symbolic.\n",
    "    wrong_fragment: continuous.\n",
    "    urgent: continuous.\n",
    "    hot: continuous.\n",
    "    num_failed_logins: continuous.\n",
    "    logged_in: symbolic.\n",
    "    num_compromised: continuous.\n",
    "    root_shell: continuous.\n",
    "    su_attempted: continuous.\n",
    "    num_root: continuous.\n",
    "    num_file_creations: continuous.\n",
    "    num_shells: continuous.\n",
    "    num_access_files: continuous.\n",
    "    num_outbound_cmds: continuous.\n",
    "    is_host_login: symbolic.\n",
    "    is_guest_login: symbolic.\n",
    "    count: continuous.\n",
    "    srv_count: continuous.\n",
    "    serror_rate: continuous.\n",
    "    srv_serror_rate: continuous.\n",
    "    rerror_rate: continuous.\n",
    "    srv_rerror_rate: continuous.\n",
    "    same_srv_rate: continuous.\n",
    "    diff_srv_rate: continuous.\n",
    "    srv_diff_host_rate: continuous.\n",
    "    dst_host_count: continuous.\n",
    "    dst_host_srv_count: continuous.\n",
    "    dst_host_same_srv_rate: continuous.\n",
    "    dst_host_diff_srv_rate: continuous.\n",
    "    dst_host_same_src_port_rate: continuous.\n",
    "    dst_host_srv_diff_host_rate: continuous.\n",
    "    dst_host_serror_rate: continuous.\n",
    "    dst_host_srv_serror_rate: continuous.\n",
    "    dst_host_rerror_rate: continuous.\n",
    "    dst_host_srv_rerror_rate: continuous.\n",
    "\n",
    "\n",
    "通过对41个固定特征属性的分析，比较能体现出状态变化的是前31个特征属性，其中9个离散型，22个连续型。因此对连接记录的分析处理是针对该31个特征属性。接下来将这31个特征属性进行总结分析。\n",
    "\n",
    "|数据样本（41个特征）|标识类别|\n",
    "|---|---|\n",
    "|2, tcp, smtp, SF, 1684, 363, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 104, 66, 0.63, 0.03, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00| normal|\n",
    "|0, tcp, private, REJ, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 1, 0.00, 0.00, 1.00, 1.00, 0.03, 0.55, 0.00, 208, 1, 0.00, 0.11, 0.18, 0.00, 0.01, 0.00, 0.42, 1.00| portsweep|\n",
    "|0, tcp, smtp, SF, 787, 329, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 76, 117, 0.49, 0.08, 0.01, 0.02, 0.00, 0.00, 0.00, 0.00| normal|\n",
    "\n",
    "上面是数据集中的3条记录，以CSV格式写成，加上最后的标记（label），一共有42项，其中前41项特征分为4大类，下面按顺序解释各个特征的含义："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. TCP连接基本特征（共9种）**\n",
    "\n",
    "基本连接特征包含了一些连接的基本属性，如连续时间，协议类型，传送的字节数等。\n",
    "\n",
    "    （1）duration. 连接持续时间，以秒为单位，连续类型。范围是 [0, 58329] 。它的定义是从TCP连接以3次握手建立算起，到FIN/ACK连接结束为止的时间；若为UDP协议类型，则将每个UDP数据包作为一条连接。数据集中出现大量的duration = 0 的情况，是因为该条连接的持续时间不足1秒。\n",
    "    （2）protocol_type. 协议类型，离散类型，共有3种：TCP, UDP, ICMP。\n",
    "    （3）service. 目标主机的网络服务类型，离散类型，共有70种。’aol’, ‘auth’, ‘bgp’, ‘courier’, ‘csnet_ns’, ‘ctf’, ‘daytime’, ‘discard’, ‘domain’, ‘domain_u’, ‘echo’, ‘eco_i’, ‘ecr_i’, ‘efs’, ‘exec’, ‘finger’, ‘ftp’, ‘ftp_data’, ‘gopher’, ‘harvest’, ‘hostnames’, ‘http’, ‘http_2784′, ‘http_443′, ‘http_8001′, ‘imap4′, ‘IRC’, ‘iso_tsap’, ‘klogin’, ‘kshell’, ‘ldap’, ‘link’, ‘login’, ‘mtp’, ‘name’, ‘netbios_dgm’, ‘netbios_ns’, ‘netbios_ssn’, ‘netstat’, ‘nnsp’, ‘nntp’, ‘ntp_u’, ‘other’, ‘pm_dump’, ‘pop_2′, ‘pop_3′, ‘printer’, ‘private’, ‘red_i’, ‘remote_job’, ‘rje’, ‘shell’, ‘smtp’, ‘sql_net’, ‘ssh’, ‘sunrpc’, ‘supdup’, ‘systat’, ‘telnet’, ‘tftp_u’, ‘tim_i’, ‘time’, ‘urh_i’, ‘urp_i’, ‘uucp’, ‘uucp_path’, ‘vmnet’, ‘whois’, ‘X11′, ‘Z39_50′。\n",
    "    （4）flag. 连接正常或错误的状态，离散类型，共11种。’OTH’, ‘REJ’, ‘RSTO’, ‘RSTOS0′, ‘RSTR’, ‘S0′, ‘S1′, ‘S2′, ‘S3′, ‘SF’, ‘SH’。它表示该连接是否按照协议要求开始或完成。例如SF表示连接正常建立并终止；S0表示只接到了SYN请求数据包，而没有后面的SYN/ACK。其中SF表示正常，其他10种都是error。\n",
    "    （5）src_bytes. 从源主机到目标主机的数据的字节数，连续类型，范围是 [0, 1379963888]。\n",
    "    （6）dst_bytes. 从目标主机到源主机的数据的字节数，连续类型，范围是 [0. 1309937401]。\n",
    "    （7）land. 若连接来自/送达同一个主机/端口则为1，否则为0，离散类型，0或1。\n",
    "    （8）wrong_fragment. 错误分段的数量，连续类型，范围是 [0, 3]。\n",
    "    （9）urgent. 加急包的个数，连续类型，范围是[0, 14]。\n",
    "    \n",
    "**2. TCP连接的内容特征（共13种）**\n",
    "\n",
    "对于U2R和R2L之类的攻击，由于它们不像DoS攻击那样在数据记录中具有频繁序列模式，而一般都是嵌入在数据包的数据负载里面，单一的数据包和正常连接没有什么区别。为了检测这类攻击，Wenke Lee等从数据内容里面抽取了部分可能反映入侵行为的内容特征，如登录失败的次数等。\n",
    "\n",
    "    （10）hot. 访问系统敏感文件和目录的次数，连续，范围是 [0, 101]。例如访问系统目录，建立或执行程序等。\n",
    "    （11）num_failed_logins. 登录尝试失败的次数。连续，[0, 5]。\n",
    "    （12）logged_in. 成功登录则为1，否则为0，离散，0或1。\n",
    "    （13）num_compromised. compromised条件（**）出现的次数，连续，[0, 7479]。\n",
    "    （14）root_shell. 若获得root shell 则为1，否则为0，离散，0或1。root_shell是指获得超级用户权限。\n",
    "    （15）su_attempted. 若出现”su root” 命令则为1，否则为0，离散，0或1。\n",
    "    （16）num_root. root用户访问次数，连续，[0, 7468]。\n",
    "    （17）num_file_creations. 文件创建操作的次数，连续，[0, 100]。\n",
    "    （18）num_shells. 使用shell命令的次数，连续，[0, 5]。\n",
    "    （19）num_access_files. 访问控制文件的次数，连续，[0, 9]。例如对 /etc/passwd 或 .rhosts 文件的访问。\n",
    "    （20）num_outbound_cmds. 一个FTP会话中出站连接的次数，连续，0。数据集中这一特征出现次数为0。\n",
    "    （21）is_hot_login.登录是否属于“hot”列表（***），是为1，否则为0，离散，0或1。例如超级用户或管理员登录。\n",
    "    （22）is_guest_login. 若是guest 登录则为1，否则为0，离散，0或1。\n",
    "    \n",
    "**3. 基于时间的网络流量统计特征 （共9种，23～31）**\n",
    "\n",
    "由于网络攻击事件在时间上有很强的关联性，因此统计出当前连接记录与之前一段时间内的连接记录之间存在的某些联系，可以更好的反映连接之间的关系。这类特征又分为两种集合：一个是 “same host”特征，只观察在过去两秒内与当前连接有相同目标主机的连接，例如相同的连接数，在这些相同连接与当前连接有相同的服务的连接等等；另一个是 “same service”特征，只观察过去两秒内与当前连接有相同服务的连接，例如这样的连接有多少个，其中有多少出现SYN错误或者REJ错误。\n",
    "\n",
    "    （23）count. 过去两秒内，与当前连接具有相同的目标主机的连接数，连续，[0, 511]。\n",
    "    （24）srv_count. 过去两秒内，与当前连接具有相同服务的连接数，连续，[0, 511]。\n",
    "    （25）serror_rate. 过去两秒内，在与当前连接具有相同目标主机的连接中，出现“SYN” 错误的连接的百分比，连续，[0.00, 1.00]。\n",
    "    （26）srv_serror_rate. 过去两秒内，在与当前连接具有相同服务的连接中，出现“SYN” 错误的连接的百分比，连续，[0.00, 1.00]。\n",
    "    （27）rerror_rate. 过去两秒内，在与当前连接具有相同目标主机的连接中，出现“REJ” 错误的连接的百分比，连续，[0.00, 1.00]。\n",
    "    （28）srv_rerror_rate. 过去两秒内，在与当前连接具有相同服务的连接中，出现“REJ” 错误的连接的百分比，连续，[0.00, 1.00]。\n",
    "    （29）same_srv_rate. 过去两秒内，在与当前连接具有相同目标主机的连接中，与当前连接具有相同服务的连接的百分比，连续，[0.00, 1.00]。\n",
    "    （30）diff_srv_rate. 过去两秒内，在与当前连接具有相同目标主机的连接中，与当前连接具有不同服务的连接的百分比，连续，[0.00, 1.00]。\n",
    "    （31）srv_diff_host_rate. 过去两秒内，在与当前连接具有相同服务的连接中，与当前连接具有不同目标主机的连接的百分比，连续，[0.00, 1.00]。\n",
    "\n",
    "注：这一大类特征中，23、25、27、29、30这5个特征是 “same host” 特征，前提都是与当前连接具有相同目标主机的连接；24、26、28、31这4个特征是 “same service” 特征，前提都是与当前连接具有相同服务的连接。\n",
    "\n",
    "**4. 基于主机的网络流量统计特征 （共10种，32～41）**\n",
    "基于时间的流量统计只是在过去两秒的范围内统计与当前连接之间的关系，而在实际入侵中，有些 Probing攻击使用慢速攻击模式来扫描主机或端口，当它们扫描的频率大于2秒的时候，基于时间的统计方法就无法从数据中找到关联。所以Wenke Lee等按照目标主机进行分类，使用一个具有100个连接的时间窗，统计当前连接之前100个连接记录中与当前连接具有相同目标主机的统计信息。\n",
    "\n",
    "    （32）dst_host_count. 前100个连接中，与当前连接具有相同目标主机的连接数，连续，[0, 255]。\n",
    "    （33）dst_host_srv_count. 前100个连接中，与当前连接具有相同目标主机相同服务的连接数，连续，[0, 255]。\n",
    "    （34）dst_host_same_srv_rate. 前100个连接中，与当前连接具有相同目标主机相同服务的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （35）dst_host_diff_srv_rate. 前100个连接中，与当前连接具有相同目标主机不同服务的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （36）dst_host_same_src_port_rate. 前100个连接中，与当前连接具有相同目标主机相同源端口的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （37）dst_host_srv_diff_host_rate. 前100个连接中，与当前连接具有相同目标主机相同服务的连接中，与当前连接具有不同源主机的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （38）dst_host_serror_rate. 前100个连接中，与当前连接具有相同目标主机的连接中，出现SYN错误的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （39）dst_host_srv_serror_rate. 前100个连接中，与当前连接具有相同目标主机相同服务的连接中，出现SYN错误的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （40）dst_host_rerror_rate. 前100个连接中，与当前连接具有相同目标主机的连接中，出现REJ错误的连接所占的百分比，连续，[0.00, 1.00]。\n",
    "    （41）dst_host_srv_rerror_rate. 前100个连接中，与当前连接具有相同目标主机相同服务的连接中，出现REJ错误的连接所占的百分比，连续，[0.00, 1.00]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KDD99数据集是由DARPA98数据集经过数据挖掘和预处理后得到的。但KDD99与DARPA98并不是一一对应的，Wende Lee等人在处理原始连接数据时将部分重复数据去除，例如进行DoS攻击时产生大量相同的连接记录，就只取攻击过程中5分钟内的连接记录作为该攻击类型的数据集。同时，也会随机抽取正常(normal)数据连接作为正常数据集。\n",
    "\n",
    "KDD99数据集总共由500万条记录构成，还提供一个10%抽样的训练子集kddcup.data_10_percent( 约49万条数据记录)和测试子集kddcup.testdata.unlabeled_10_percent( 约31万条数据记录)，在实验研究中, 一般使用抽样子集，其样本分布如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|标签|类别|训练集（10%）|测试集（Corrected）|\n",
    " |---|---|---|---|\n",
    "|0|NORMAL|97278|60593|\n",
    "|1|PROBE|4107|4166| \n",
    "||ipsweep|1247|306|\n",
    "||mscan|/|1053|\n",
    "||nmap|231|84| \n",
    "||portsweep|1040|354|\n",
    "||saint|/|736|\n",
    "||satan|1589|1633|\n",
    "|2|DOS|391458|229853| \n",
    "||apache2|/|794| \n",
    "||back|2203|1098| \n",
    "||land|21|9|\n",
    "||mailbomb|/|5000|\n",
    "||neptune|107201|58001|\n",
    "||pod|264|87|\n",
    "||processtable|/|759|\n",
    "||smurf|280790|164091|\n",
    "||teardrop|979|12|\n",
    "||udpstorm|/|2|\n",
    "|3|U2R|52|228| \n",
    "||buffer_overflow|30|22| \n",
    "||httptunnel|/|158|\n",
    "||loadmodule|9|2| \n",
    "||perl|3|2| \n",
    "||ps|/|16| \n",
    "||rootkit|10|13| \n",
    "||sqlattack|/|2| \n",
    "||xterm|/|13|\n",
    "|4|R2L|1126|16189| \n",
    "||ftp_write|8|3| \n",
    "||guess_passwd|53|4367| \n",
    "||imap|12|1| \n",
    "||multihop|7|18| \n",
    "||named|/|17|\n",
    "||phf|4|2| \n",
    "||sendmail|/|17| \n",
    "||snmpgetattack|/|7741| \n",
    "||snmpguess|/|2406| \n",
    "||spy|2|/| \n",
    "||warezclient|1020|/| \n",
    "||warezmaster|20|1602| \n",
    "||worm|/|2| \n",
    "||xlock|/|9| \n",
    "||xsnoop|/|4|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. 训练集和测试集分别为KDD99数据集中的10%训练样本和corrected 的测试样本；\n",
    "    2. “/”表示该种攻击类型只在测试集（或训练集）中出现，而未在训练集（或测试集）中出现； \n",
    "\n",
    "如上表，同DARPA98一样，KDD99将攻击类型分为4类，然后又细分为39小类，每一类代表一种攻击类型，类型名被标记在训练数据集每一行记录的最后一项。\n",
    "从表中可以看出，训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现，这样设计的目的是检验分类器模型的泛化能力，**对未知攻击类型的检测能力是评价入侵检测系统好坏的重要指标**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用和评价\n",
    "## KDD 99数据集的应用\n",
    "建立KDD99数据集的目的就是为入侵检测系统提供统一的性能评价基准，它的应用一般局限在学术范围内，用来检验入侵检测算法的好坏。\n",
    "\n",
    "入侵检测的方法从根本上讲就是**设计一个分类器**，能将数据流中的正常与异常数据区分出来，从而实现对攻击行为的报警。通常的，我们将数据集中的的10%训练集来训练分类器，然后用corrected测试集测试分类器性能，这个分类器可以是**基于贝叶斯的、决策树的、神经网络的或者是支持向量机的**。有关分类器的设计，请自行了解相关文献。\n",
    "\n",
    "**特征选择**是KDD99数据集的另一个主要应用。KDD99数据集中，每个连接有41个特征，对于一个分类器来说，要从这么多特征中提取规则是费时且不精确的，这体现在一些无关或冗余的特征往往会降低分类器模型的检测精度和速度。而且对于从原始的TCPdump数据中提取特征这一过程，也将是困难和费时的，这对于在线入侵检测系统是致命的。因此去除冗余特征或不重要特征，对于提高分类器训练速度和检测精度来说，是必要的。要说明的是对于不同的分类器来说，最优的特征子集可以是不同的。\n",
    "\n",
    "\n",
    "## KDD 99数据集的评价\n",
    "前面说过，KDD 99数据集是入侵检测领域的事实Benchmark，为基于计算智能的网络入侵检测研究奠定了基础，从那以后很多学者开始研究入侵检测算法，当然不能不提到众所周知、臭名昭著的“**功夫网**”。实际上“功夫网”就是一个大规模的入侵检测系统，科技这把双刃剑在让我们远离恶意攻击的同时，也让我们离真相越来越远。\n",
    "\n",
    "KDD99从1999年创建到2010年现在也有11个年头了，当年的实验条件和攻击手段放到今天早已过时，而且从原来的**网络层攻击**进化为针对**应用层**的攻击，例如跨站脚本、数据库注入等等（当然，针对应用层攻击自有新的解决方案）。你可以说，要解决这个问题，重新做一遍98年那个实验，用新的设备新的攻击手段，产生新的数据集不就行了吗？事实是据我所知还没有学术组织公开新的数据集，安全软件公司里肯定有足够的数据库，当然，人家是不会共享出来的。另一个解决办法是你自己搭建网络环境，自己做实验，就是累点，当然可行。\n",
    "\n",
    "暂且不管数据新旧，KDD99数据集存在的一些原生的缺陷却不能被忽略。这里给出几篇介绍KDD99缺陷的文献，供大家参考：\n",
    "    \n",
    "    [1] The 1998 Lincoln Laboratory IDS Evaluation A Critique. by John McHugh\n",
    "    [2] Testing Intrusion Detection Systems: A Critique of the 1998 and 1999 DARPA Intrusion Detection System Evaluations as Performed by Lincoln Laboratory. by John McHugh\n",
    "    [3] The Comparison of IP Networks. by ST Brugger\n",
    "    [4] KDD Cup ’99 dataset (Network Intrusion) considered harmful. by ST Brugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集预处理\n",
    "参考：https://blog.csdn.net/asialee_bird/article/details/80491256\n",
    "\n",
    "入侵检测实验一般使用的是KDD CUP99中的kddcup_data_10percent数据集。由于数据集中包含有符号型的数据属性，不适合聚类测试，对于连续型特征属性，各属性的度量方法不一样。一般而言，所用的度量单位越小，变量可能的值域就越大，这样对聚类结果的影响也越大，即在计算数据间距离时对聚类产生的影响越大。为了避免由于属性度量的差异对聚类产生的影响，需要对特征属性值进行标准化等预处理。\n",
    "\n",
    "## 字符型特征转换为数值型特征\n",
    "即符号型特征数值化。Python3对KDD CUP99数据集预处理代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#在下面添加此代码以显示单元格中的所有输出\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:84: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 49.521753900000476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:88: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#kdd99数据集预处理\n",
    "#将kdd99符号型数据转化为数值型数据 \n",
    "\n",
    "#coding:utf-8 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "global label_list  #label_list为全局变量 \n",
    "\n",
    "#定义kdd99数据预处理函数\n",
    "def preHandel_TraindataDigit():\n",
    "    #训练集源文件\n",
    "    source_file='E:/DataSet/KDDCUP99/DataSet/kddcup.data_10_percent/kddcup.data_10_percent_corrected'\n",
    "    #保存训练集\n",
    "    handled_file='E:/DataSet/KDDCUP99/DataSet/kddcup.data_10_percent/kddcup.data_10_percent_corrected_2csv.csv'\n",
    "\n",
    "    data_file=open(handled_file,'w',newline='')     #python3.x中添加newline=''这一参数使写入的文件没有多余的空行\n",
    "    with open(source_file,'r') as data_source:\n",
    "        csv_reader=csv.reader(data_source)\n",
    "        csv_writer=csv.writer(data_file)\n",
    "        count=0   #记录数据的行数，初始化为0\n",
    "        for row in csv_reader:\n",
    "            temp_line=np.array(row)   #将每行数据存入temp_line数组里\n",
    "            temp_line[1]=handleProtocol(row)   #将源文件行中3种协议类型转换成数字标识\n",
    "            \n",
    "            tmp=handleService(row)    #将源文件行中70种网络服务类型转换成数字标识\n",
    "            if tmp==-1:continue\n",
    "            temp_line[2]=tmp\n",
    "            temp_line[3]=handleFlag(row)       #将源文件行中11种网络连接状态转换成数字标识\n",
    "            temp_line[41]=handleLabel(row)   #将源文件行中23种攻击类型转换成数字标识\n",
    "            csv_writer.writerow(temp_line)\n",
    "            count+=1\n",
    "\n",
    "            #输出每行数据中所修改后的状态\n",
    "            #print(count,'status:',temp_line[1],temp_line[2],temp_line[3],temp_line[41])\n",
    "        data_file.close() \n",
    "\n",
    "#将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据\n",
    "def find_index(x,y):\n",
    "    return [i for i in range(len(y)) if y[i]==x] \n",
    "\n",
    "#定义将源文件行中3种协议类型转换成数字标识的函数\n",
    "def handleProtocol(input):\n",
    "    protocol_list=['tcp','udp','icmp']\n",
    "    if input[1] in protocol_list:\n",
    "        return find_index(input[1],protocol_list)[0] \n",
    "\n",
    "#定义将源文件行中70种网络服务类型转换成数字标识的函数\n",
    "def handleService(input):\n",
    "    service_list=['aol','auth','bgp','courier','csnet_ns','ctf','daytime','discard','domain','domain_u',\n",
    "                 'echo','eco_i','ecr_i','efs','exec','finger','ftp','ftp_data','gopher','harvest','hostnames',\n",
    "                 'http','http_2784','http_443','http_8001','imap4','IRC','iso_tsap','klogin','kshell','ldap',\n",
    "                 'link','login','mtp','name','netbios_dgm','netbios_ns','netbios_ssn','netstat','nnsp','nntp',\n",
    "                 'ntp_u','other','pm_dump','pop_2','pop_3','printer','private','red_i','remote_job','rje','shell',\n",
    "                 'smtp','sql_net','ssh','sunrpc','supdup','systat','telnet','tftp_u','tim_i','time','urh_i','urp_i',\n",
    "                 'uucp','uucp_path','vmnet','whois','X11','Z39_50']\n",
    "    if input[2] in service_list:\n",
    "        return find_index(input[2],service_list)[0] \n",
    "    else:return -1\n",
    "\n",
    "#定义将源文件行中11种网络连接状态转换成数字标识的函数\n",
    "def handleFlag(input):\n",
    "    flag_list=['OTH','REJ','RSTO','RSTOS0','RSTR','S0','S1','S2','S3','SF','SH']\n",
    "    if input[3] in flag_list:\n",
    "        return find_index(input[3],flag_list)[0] \n",
    "\n",
    "#定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)\n",
    "\n",
    "def handleLabel(input):\n",
    "    #label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',\n",
    "    # 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',\n",
    "    # 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n",
    "    # 'spy.', 'rootkit.']\n",
    "    global label_list  #在函数内部使用全局变量并修改它\n",
    "    if input[41] in label_list:\n",
    "        return find_index(input[41],label_list)[0]\n",
    "    else:\n",
    "        label_list.append(input[41])\n",
    "        return find_index(input[41],label_list)[0] \n",
    "\n",
    "if __name__=='__main__':\n",
    "    start_time=time.clock()\n",
    "    global label_list   #声明一个全局变量的列表并初始化为空\n",
    "    label_list=[]\n",
    "    preHandel_TraindataDigit()\n",
    "    end_time=time.clock()\n",
    "    print(\"Running time:\",(end_time-start_time))  #输出程序运行时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尤其是在测试文件中，有些服务不在列表里面，如第136489行为icmp服务，这样的串将是none值，而不是数字，故删除。\n",
    "\n",
    "如果是测试集数值化，则只是不需要对最后一列进行处理，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据\\ndef find_index(x,y):\\n    return [i for i in range(len(y)) if y[i]==x] \\n\\n#定义将源文件行中3种协议类型转换成数字标识的函数\\ndef handleProtocol(input):\\n    protocol_list=['tcp','udp','icmp']\\n    if input[1] in protocol_list:\\n        return find_index(input[1],protocol_list)[0] \\n\\n#定义将源文件行中70种网络服务类型转换成数字标识的函数\\ndef handleService(input):\\n    service_list=['aol','auth','bgp','courier','csnet_ns','ctf','daytime','discard','domain','domain_u',\\n                 'echo','eco_i','ecr_i','efs','exec','finger','ftp','ftp_data','gopher','harvest','hostnames',\\n                 'http','http_2784','http_443','http_8001','imap4','IRC','iso_tsap','klogin','kshell','ldap',\\n                 'link','login','mtp','name','netbios_dgm','netbios_ns','netbios_ssn','netstat','nnsp','nntp',\\n                 'ntp_u','other','pm_dump','pop_2','pop_3','printer','private','red_i','remote_job','rje','shell',\\n                 'smtp','sql_net','ssh','sunrpc','supdup','systat','telnet','tftp_u','tim_i','time','urh_i','urp_i',\\n                 'uucp','uucp_path','vmnet','whois','X11','Z39_50']\\n    if input[2] in service_list:\\n        return find_index(input[2],service_list)[0] \\n\\n#定义将源文件行中11种网络连接状态转换成数字标识的函数\\ndef handleFlag(input):\\n    flag_list=['OTH','REJ','RSTO','RSTOS0','RSTR','S0','S1','S2','S3','SF','SH']\\n    if input[3] in flag_list:\\n        return find_index(input[3],flag_list)[0] \\n    \\n\\n#定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)\\ndef handleLabel(input):\\n    #label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',\\n    # 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',\\n    # 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\\n    # 'spy.', 'rootkit.']\\n    global label_list  #在函数内部使用全局变量并修改它\\n    if input[41] in label_list:\\n        return find_index(input[41],label_list)[0]\\n    else:\\n        label_list.append(input[41])\\n        return find_index(input[41],label_list)[0] \\n\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:82: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 28.993661900000006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:86: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#kdd99数据集预处理\n",
    "#将kdd99符号型数据转化为数值型数据 \n",
    "\n",
    "#coding:utf-8 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "global label_list  #label_list为全局变量 \n",
    "\n",
    "#定义kdd99数据预处理函数\n",
    "def preHandel_TestdataDigit():\n",
    "    #测试集源文件\n",
    "    source_file='E:/DataSet/KDDCUP99/DataSet/kddcup.testdata.unlabeled_10_percent/kddcup.testdata.unlabeled_10_percent'\n",
    "   \n",
    "    #保存测试集\n",
    "    handled_file='E:/DataSet/KDDCUP99/DataSet/kddcup.testdata.unlabeled_10_percent/kddcup.testdata.unlabeled_10_percent_2csv.csv'\n",
    "\n",
    "    data_file=open(handled_file,'w',newline='')     #python3.x中添加newline=''这一参数使写入的文件没有多余的空行\n",
    "    with open(source_file,'r') as data_source:\n",
    "        csv_reader=csv.reader(data_source)\n",
    "        csv_writer=csv.writer(data_file)\n",
    "        count=0   #记录数据的行数，初始化为0\n",
    "        for row in csv_reader:\n",
    "            temp_line=np.array(row)   #将每行数据存入temp_line数组里\n",
    "            temp_line[1]=handleProtocol(row)   #将源文件行中3种协议类型转换成数字标识\n",
    "            temp_line[2]=handleService(row)    #将源文件行中70种网络服务类型转换成数字标识\n",
    "            temp_line[3]=handleFlag(row)       #将源文件行中11种网络连接状态转换成数字标识\n",
    "            #temp_line[41]=handleLabel(row)   #将源文件行中23种攻击类型转换成数字标识\n",
    "            csv_writer.writerow(temp_line)\n",
    "            count+=1\n",
    "\n",
    "            #输出每行数据中所修改后的状态\n",
    "            #print(count,'status:',temp_line[1],temp_line[2],temp_line[3],temp_line[41])\n",
    "            #print(count,'status:',temp_line[1],temp_line[2],temp_line[3])\n",
    "        data_file.close() \n",
    "'''\n",
    "#将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据\n",
    "def find_index(x,y):\n",
    "    return [i for i in range(len(y)) if y[i]==x] \n",
    "\n",
    "#定义将源文件行中3种协议类型转换成数字标识的函数\n",
    "def handleProtocol(input):\n",
    "    protocol_list=['tcp','udp','icmp']\n",
    "    if input[1] in protocol_list:\n",
    "        return find_index(input[1],protocol_list)[0] \n",
    "\n",
    "#定义将源文件行中70种网络服务类型转换成数字标识的函数\n",
    "def handleService(input):\n",
    "    service_list=['aol','auth','bgp','courier','csnet_ns','ctf','daytime','discard','domain','domain_u',\n",
    "                 'echo','eco_i','ecr_i','efs','exec','finger','ftp','ftp_data','gopher','harvest','hostnames',\n",
    "                 'http','http_2784','http_443','http_8001','imap4','IRC','iso_tsap','klogin','kshell','ldap',\n",
    "                 'link','login','mtp','name','netbios_dgm','netbios_ns','netbios_ssn','netstat','nnsp','nntp',\n",
    "                 'ntp_u','other','pm_dump','pop_2','pop_3','printer','private','red_i','remote_job','rje','shell',\n",
    "                 'smtp','sql_net','ssh','sunrpc','supdup','systat','telnet','tftp_u','tim_i','time','urh_i','urp_i',\n",
    "                 'uucp','uucp_path','vmnet','whois','X11','Z39_50']\n",
    "    if input[2] in service_list:\n",
    "        return find_index(input[2],service_list)[0] \n",
    "\n",
    "#定义将源文件行中11种网络连接状态转换成数字标识的函数\n",
    "def handleFlag(input):\n",
    "    flag_list=['OTH','REJ','RSTO','RSTOS0','RSTR','S0','S1','S2','S3','SF','SH']\n",
    "    if input[3] in flag_list:\n",
    "        return find_index(input[3],flag_list)[0] \n",
    "    \n",
    "\n",
    "#定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)\n",
    "def handleLabel(input):\n",
    "    #label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',\n",
    "    # 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',\n",
    "    # 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n",
    "    # 'spy.', 'rootkit.']\n",
    "    global label_list  #在函数内部使用全局变量并修改它\n",
    "    if input[41] in label_list:\n",
    "        return find_index(input[41],label_list)[0]\n",
    "    else:\n",
    "        label_list.append(input[41])\n",
    "        return find_index(input[41],label_list)[0] \n",
    "'''\n",
    "if __name__=='__main__':\n",
    "    start_time=time.clock()\n",
    "    global label_list   #声明一个全局变量的列表并初始化为空\n",
    "    label_list=[]\n",
    "    preHandel_TestdataDigit()\n",
    "    end_time=time.clock()\n",
    "    print(\"Running time:\",(end_time-start_time))  #输出程序运行时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值标准化和归一化\n",
    "设$x_{ij}'$为$x_{ij}$**标准化**后的结果。公式如下：$$x_{ij}'=\\frac{x_{ij}-AVG_j}{STAD_i}$$其中$AVG_j$为第j列均值，$STAD_j$为绝对偏差的平均,n为样例总数：\n",
    "$$AVG_j=\\frac{1}{n}\\sum_ix_{ij}$$\n",
    "$$STAD_j=\\frac{1}{n}\\sum_i|x_{ij}-AVG_j|$$在上述计算时，要做如下判断：\n",
    "\n",
    "（1）如果$AVG_j=0$，则$x_{ij}'=0$\n",
    "\n",
    "（2）如果$STAD_j=0$，则$x_{ij}'=0$\n",
    "\n",
    "**归一化**是将标准化后的每个数值归于[0,1]区间，设归一化后的数据为$x_{ij}''$$$x_{ij}''=\\frac{x_{ij}'-x_{min}}{x_{max}-x_{min}}$$其中，$x_{max},x_{min}$表示$x_{ij}'$中第j列的最大最小值。相应地，这里的归一化就是最大最小归一化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用的是平均绝对偏差，和标准差$\\sigma _j=\\frac{1}{n-1}\\sqrt{\\sum_i(x_{ij}-AVG_j)^2}$相比，对孤立点具有更好的鲁棒性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#训练数据标准化和归一化\n",
    "import numpy as np\n",
    "#import math\n",
    "#使用numpy读写csv文件，标准化和归一化不包含标签数据\n",
    "def Handle_TraindataStand():\n",
    "    source_file = \"E:/DataSet/KDDCUP99/DataSet/kddcup.data_10_percent/kddcup.data_10_percent_corrected_2csv.csv\"\n",
    "    handled_file = \"E:/DataSet/KDDCUP99/DataSet/kddcup.data_10_percent/kddcup.data_10_percent_corrected_2csv_2pre.csv\"\n",
    "    \n",
    "    source_data= np.loadtxt(open(source_file,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "    source_label=source_data[:,41]\n",
    "    source_matrix = source_data[:,0:-1]\n",
    "    source_mean=np.mean(source_matrix, axis=0)#计算每一列均值\n",
    "    source_mae=np.mean(abs(source_matrix-source_mean), axis=0)#计算每一列的平均标准偏差\n",
    "    source_stand=(source_matrix-source_mean)/source_mae#计算标准化数据\n",
    "    source_normed= np.mat(source_stand / source_stand.max(axis=0))#对列进行归一化\n",
    "    #判断\n",
    "    zeros=np.zeros((source_matrix.shape[0],1))\n",
    "    #print(type(source_mean))\n",
    "    for i in range(len(source_mean)):\n",
    "        if  source_mean[i] ==0.0 or np.isnan(source_mae[i]):\n",
    "            #print(source_normed[:,i].shape,zeros.shape)\n",
    "            source_normed[:,i]=zeros\n",
    "    #合并两个部分:训练数据和标签\n",
    "    source_ret=np.column_stack((source_normed,source_label))#增加了一列标签之后，再保存\n",
    "    #保存标准化归一化后的数据\n",
    "    np.savetxt(handled_file, source_ret, delimiter = ',')\n",
    "    return source_ret,source_normed,source_label#第一个返回值最后一列为标签\n",
    "    \n",
    "train_data,Train,Label=Handle_TraindataStand()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对测试集而言，没有标签，每个样例只有41列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#标准化和归一化测试数据\n",
    "import numpy as np\n",
    "#import math\n",
    "#import csv\n",
    "#使用numpy读写csv文件，标准化和归一化测试数据\n",
    "def Handle_TestdataStand():\n",
    "    source_file =  \"E:/DataSet/KDDCUP99/DataSet/kddcup.testdata.unlabeled_10_percent/kddcup.testdata.unlabeled_10_percent_2csv.csv\"\n",
    "    handled_file = \"E:/DataSet/KDDCUP99/DataSet/kddcup.testdata.unlabeled_10_percent/kddcup.testdata.unlabeled_10_percent_2csv_2pre.csv\"\n",
    "    \n",
    "    source_matrix = np.loadtxt(open(source_file,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "    source_mean=np.mean(source_matrix, axis=0)#计算每一列均值\n",
    "    source_mae=np.mean(abs(source_matrix-source_mean), axis=0)#计算每一列的平均标准偏差\n",
    "    source_stand=(source_matrix-source_mean)/source_mae#计算标准化数据\n",
    "    source_normed= np.mat(source_stand / source_stand.max(axis=0))#对列进行归一化\n",
    "    #判断\n",
    "    zeros=np.zeros((source_matrix.shape[0],1))\n",
    "    #print(type(source_mean))\n",
    "    for i in range(len(source_mean)):\n",
    "        if  source_mean[i] ==0.0 or np.isnan(source_mae[i]):\n",
    "            source_normed[:,i]=zeros\n",
    "    #tmp=np.argwhere(np.isnan(source_mae))\n",
    "    #print(source_stand.shape,tmp)\n",
    "    #source_normed[:,i]=zeros  \n",
    "    #保存标准化归一化后的数据\n",
    "    np.savetxt(handled_file, source_normed, delimiter = ',')\n",
    "    return source_normed#无标签数据\n",
    "    \n",
    "test_data=Handle_TestdataStand()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA数据简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51360438 0.38000479 0.05061455 0.02384023]\n",
      "[12.91448514  9.55514859  1.27269336  0.59945819]\n",
      "4\n",
      "[[ 1.69668962e-04 -2.95705191e-01  8.32652977e-02 -2.37390110e-01\n",
      "   1.05746680e-06  1.99950205e-05  1.27630833e-05  3.59052350e-04\n",
      "   1.48858363e-06  2.06127321e-04  8.57962401e-06  1.45790647e-02\n",
      "   2.25118884e-06  2.00372142e-05  4.86138725e-06  3.16693427e-06\n",
      "   9.12739573e-06  1.18117824e-05  1.19427639e-05  0.00000000e+00\n",
      "   0.00000000e+00  3.33938880e-04 -2.36472499e-01 -2.78590819e-01\n",
      "   9.91120364e-02  9.90558410e-02  2.49326651e-02  2.49296824e-02\n",
      "  -4.62210449e-01  9.17693149e-03  3.37967428e-03 -1.35943501e-01\n",
      "  -4.14979454e-01 -4.28212890e-01  1.13236125e-02 -2.93009768e-01\n",
      "   9.43669668e-04  9.91327314e-02  9.90227657e-02  2.49957334e-02\n",
      "   2.48496133e-02]\n",
      " [-4.40731215e-05 -1.09125147e-01 -1.18576198e-02  6.92852674e-02\n",
      "   5.75081130e-07  1.05297357e-04  4.42727872e-05  1.01577341e-04\n",
      "   3.79773623e-06  2.87045882e-04  2.34002987e-05  9.43930081e-02\n",
      "   5.69762156e-06  8.10921728e-05  8.06398588e-06  7.05545503e-06\n",
      "   2.06561195e-05  2.92515109e-05  4.21057759e-05  0.00000000e+00\n",
      "   0.00000000e+00  4.30490393e-04 -1.91254039e-01 -1.13002668e-01\n",
      "  -4.82464901e-02 -4.81839734e-02  1.24597800e-03  1.21149329e-03\n",
      "   2.23220017e-01 -3.78524697e-03  1.87990732e-02 -9.04938773e-01\n",
      "   1.10336086e-01  1.66822665e-01 -3.24607641e-03 -8.00501539e-02\n",
      "   6.36667628e-03 -4.82407168e-02 -4.83441556e-02  1.53838938e-03\n",
      "   1.19286575e-03]\n",
      " [-2.98733211e-04  3.01784886e-01 -2.39192475e-02 -2.14145552e-01\n",
      "   1.36077366e-06 -8.49071504e-05  1.14667490e-04 -1.56825957e-03\n",
      "   4.66283683e-06 -1.65036406e-03  3.18450808e-05 -2.00641868e-01\n",
      "  -8.37666051e-06  1.78178385e-05 -9.03763972e-06  2.41770919e-06\n",
      "  -8.10037758e-06  1.62205200e-06 -2.13279512e-04  0.00000000e+00\n",
      "   0.00000000e+00 -1.29438620e-03  4.79457416e-01  3.23947881e-01\n",
      "   4.57202168e-02  4.55720704e-02  4.08373291e-02  3.96654045e-02\n",
      "  -2.81888625e-01  6.56215847e-03 -1.38490098e-02 -3.88054995e-01\n",
      "  -2.15697549e-01 -1.68528002e-01  4.00200333e-03  4.09172875e-01\n",
      "   7.16474404e-03  4.54470703e-02  4.56001225e-02  3.99652194e-02\n",
      "   3.94938276e-02]\n",
      " [-8.37178861e-04 -6.32895612e-02 -9.07845581e-03 -6.11679788e-01\n",
      "   1.38938851e-06 -9.18788621e-05 -7.23914432e-05 -2.04547309e-03\n",
      "  -9.29008870e-06 -7.13038276e-04  5.97958994e-05 -2.89283801e-02\n",
      "  -1.00778008e-05 -1.15811754e-04 -2.60700984e-05 -1.83490359e-05\n",
      "  -4.78191095e-05 -7.19456296e-05 -1.76270860e-05 -0.00000000e+00\n",
      "  -0.00000000e+00 -1.54833419e-03 -1.60323448e-02 -2.44995843e-02\n",
      "  -2.51693697e-01 -2.52805457e-01  2.85801623e-01  2.86792993e-01\n",
      "   5.75730398e-05  8.42800745e-03 -1.12329775e-04  6.52160826e-02\n",
      "   1.39223895e-01  1.24492549e-01  3.70416069e-04 -6.21934084e-02\n",
      "   3.64805602e-03 -2.51921153e-01 -2.52795141e-01  2.81331344e-01\n",
      "   2.81532387e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)#n_components='mle'，将自动选取特征个数n\n",
    "newX = pca.fit_transform(Train)\n",
    "\n",
    "print(pca.explained_variance_ratio_)  #方差百分比\n",
    "print(pca.explained_variance_)  #特征的方差\n",
    "print(pca.n_components_)#返回所保留的成分个数n。\n",
    "print(pca.components_) #返回具有最大方差的成分。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
