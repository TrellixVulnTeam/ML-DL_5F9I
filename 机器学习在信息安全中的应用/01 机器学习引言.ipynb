{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**主要参考教材**：\n",
    "\n",
    "**1、《机器学习实战》**\n",
    "\n",
    "2、《机器学习》（西瓜书），周志华\n",
    "\n",
    "3、《动手深度学习》，李沐\n",
    "\n",
    "4、《机器学习导论》（土耳其），范明译\n",
    "\n",
    "5、《机器学习算法原理与编程实践》，郑捷著"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Anaconda3和Python语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python3 列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://www.runoob.com/python3/python3-list.html\n",
    "\n",
    "序列是Python中最基本的数据结构。序列中的每个元素都分配一个数字 - 它的位置，或索引，第一个索引是0，第二个索引是1，依此类推。\n",
    "\n",
    "Python有6个序列的内置类型，但最常见的是列表和元组。序列都可以进行的操作包括索引，切片，加，乘，检查成员。\n",
    "\n",
    "此外，Python已经内置确定序列的长度以及确定最大和最小的元素的方法。\n",
    "\n",
    "**列表**是最常用的Python数据类型，它可以作为一个方括号内的逗号分隔值出现。列表的数据项不需要具有相同的类型\n",
    "\n",
    "**创建一个列表**，只要把逗号分隔的不同的数据项使用方括号括起来即可。如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在下面添加此代码以显示单元格中的所有输出\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Runoob'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = ['Google', 'Runoob', 1997, 2000]#定义列表，元素为不同的类型\n",
    "list2 = [1, 2, 3, 4, 5 ]\n",
    "list3 = [\"a\", \"b\", \"c\", \"d\"]\n",
    "list1[1]\n",
    "list3[2]#访问列表中的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以对列表的数据项进行**修改或更新**，你也可以使用**append()方法**来添加列表项，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2[2] = 2001\n",
    "print (\"更新后的第三个元素为 : \", list2[2])\n",
    "list2.append(\"2002年\")#尾部增加\n",
    "print (\"最后一个元素为 : \", list2[-1])\n",
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用 **del 语句来删除列表的的元素**， **remove()** 方法删除指定值的元素。如下实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2.append(\"2002年\")#尾部增加\n",
    "list2.append(5)#尾部增加\n",
    "list2.append(5)#尾部增加\n",
    "del list2[2]\n",
    "list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2.remove(5)#删除元素5\n",
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列表对 + 和 * 的操作符与字符串相似。**+ 号用于组合列表，* 号用于重复列表**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1, 2, 3])\n",
    "[1, 2, 3] + [4, 5, 6]#拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Hi!'] * 4#重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 in [1, 2, 3]#元素是否存在于列表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [1, 2, 3]: print(x, end=\" \")#迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2[-2],list2[2:4]#从右侧开始读取倒数第二个元素、切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用**嵌套列表**即在列表里创建其它列表，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['a', 'b', 'c']\n",
    "n = [1, 2, 3]\n",
    "x = [a, n]\n",
    "x,x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python3 元组\n",
    "参考：https://www.runoob.com/python3/python3-tuple.html\n",
    "Python 的元组与列表类似，不同之处在于**元组的元素不能修改**。元组使用小括号，列表使用方括号。元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup1 = ('Google', 'Runoob', 1997, 2000)\n",
    "tup2 = (1, 2, 3, 4, 5 )\n",
    "tup3 = \"a\", \"b\", \"c\", \"d\"   #  不需要括号也可以\n",
    "tup3,type(tup3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元组中只包含一个元素时，需要在元素后面添加逗号，否则括号会被当作运算符使用。\n",
    "\n",
    "元组与字符串类似，下标索引从0开始，可以进行截取，组合等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"tup1[0]: \", tup1[0])\n",
    "print (\"tup2[1:5]: \", tup2[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#元组转列表\n",
    "list(tup1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 字典\n",
    "参考：https://www.runoob.com/python3/python3-dictionary.html\n",
    "\n",
    "字典是另一种可变容器模型，且**可存储任意类型对象**。\n",
    "字典的每个**\"键值对\"**(key=>value)用冒号(:)分割，每个对之间用逗号(,)分割，整个字典包括在花括号({})中 ,格式如下所示：d = {key1 : value1, key2 : value2 }\n",
    "\n",
    "键必须是唯一的，但值则不必。值可以取任何数据类型，但键必须是不可变的，如字符串，数字或元组。\n",
    "\n",
    "一个简单的字典实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'}\n",
    "#也可如此创建字典：\n",
    "dict1 = { 'abc': 456 }\n",
    "dict2 = { 'abc': 123, 98.6: 37 }\n",
    "#访问字典的值\n",
    "dict['Alice'],type(dict['Alice']),dict2[98.6],dict[\"Cecil\"]#如果用字典里没有的键访问数据，会出错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加、修改、删除键值对\n",
    "dict['Alice'] = 8    # 更新 Age\n",
    "print(dict)\n",
    "del dict['Alice']    #删除\n",
    "print(dict)\n",
    "dict['Alice'] = \"New Alice\"  \n",
    "print(dict)\n",
    "#dict.clear()     # 清空字典\n",
    "#del dict         # 删除字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['Bob'] = \"New Alice\"  \n",
    "print(dict.keys(),dict.values())#返回列表\n",
    "for i in dict.keys() :print (i,\"\\t\",dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字典嵌套"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict[\"Alice\"]={'a':1,'b':2,'c':3}\n",
    "print(dict)\n",
    "print(dict['Alice']['a'])#引用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python3 集合\n",
    "参考：https://www.runoob.com/python3/python3-set.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集合（set）是一个无序的不重复元素序列。\n",
    "\n",
    "可以使用大括号 { } 或者 set() 函数创建集合，注意：创建一个空集合必须用 set() 而不是 { }，因为 { } 是用来创建一个空字典。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n",
    "print(basket)                      # 这里演示的是去重功能\n",
    "'orange' in basket                 # 快速判断元素是否在集合内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set('abracadabra')\n",
    "b = set('alacazam')\n",
    "print(a)\n",
    "print(a - b  )                            # 集合a中包含而集合b中不包含的元素\n",
    "print(a | b )                             # 集合a或b中包含的所有元素\n",
    "print(a & b  )                            # 集合a和b中都包含了的元素\n",
    "print(a ^ b   )                           # 不同时包含于a和b的元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一维数组二维数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念\n",
    "**对象：**在面向对象的程序设计思想中，对象是一个类的实例。在机器学习中，对象是指含有一组特征的行向量。行向量的集合最容易构造的结构就是**表**。如下图![jupyter](./Introduction-1.png)\n",
    "表中第一行种属、重量、颜色、生命周期表示特征，所有特征组合在一起构成一个行向量，也成为**特征向量**。图中有4个对象，每个对象有4个特征，每个特征用数值或非数值表示，称特征数量为**维度**。非数值特征无法参与运算，一般情况下可以编码为数值。\n",
    "\n",
    "在线性代数中，矩阵是由$m\\times n$个数组成的一个m行n列的矩形表格。前面我们知道，对象是被特征化的客观事物，表是容纳这些对象的容器，也即，**对象是表中的元素，表是对象的集合**。但是这个集合有点特殊，即表中的每个对象都有相同的特征和维度，对象对于每个特征都有取值。这样，矩阵就可以理解为具有相同特征和维度的对象的集合，表现一张二维的数据表。\n",
    "\n",
    "**一个对象表示为矩阵中一行，一个特征表示为矩阵中的一列**，每个特征都是数值型的取值。在机器学习中，特征值的取值范围构成的矩阵空间应具有完整性，即能够反映出事物的空间形式或变化。\n",
    "\n",
    "Numpy函数包提供了专门矩阵数据结构和线性代数库。Numpy函数库存在两种不同的数据类型，**矩阵matrix和数组array**。matrix是包含在array里的，是Array的一个小的分支，必须是2维。所以matrix 拥有array的所有特性，主要优势是乘法运算相对简单。\n",
    "\n",
    "数组，顾名思义，是数据的组合。它数组在应用上属于数据的容器，不仅仅是一种基础的数据类型，更是一种基础的数据结构。\n",
    "\n",
    "Python中，**numpy**（常用于数学计算）和**Pandas**（数据分析常用包，可方便地对表结构进行分析）这两个常用的数据包均可以用于表示数组。\n",
    "\n",
    "Pandas安装命令conda install pandas。在引用时，一般用下面语句："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习的本质是数学，是数学在数据上的应用。python的**Numpy函数库**专注于对于线性代数的处理，支持维度数组与矩阵计算并提供大量的数学函数库。NumPy函数库是Python开发环境的一个独立模块，大多数发行版没有默认安装Numpy函数库，因此在安装python之后必须单独安装Numpy函数库。在anaconda环境的python shell中输入**conda install numpy**命令，可以完成安装，如果需要对已经安装的Numpy进行更新，使用conda update numpy命令。\n",
    "\n",
    "在使用Numpy模块之前，需要将Numpy函数库中的所有模块引入当前的命名空间。\n",
    "\n",
    "Python中，Pandas时数据分析常用包，可方便地对表结构进行分析，安装命令为**conda install pandas**，若未安装Anaconda，使用Python自带的包管理工具pip来安装：**pip install pandas**。numpy和Pandas这两个常用的数据包均可以用于表示数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #导入Numpy包\n",
    "import pandas as pd\n",
    "print(pd.__version__) # 打印pandas版本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一维数组\n",
    "### Numpy一维数组\n",
    "参考：https://zhuanlan.zhihu.com/p/115275833\n",
    "\n",
    "在python中，用列表也可以表示数组，但是用Numpy表示的一维数组具有**统计功能**（如**平均值mean()，标准差std()）和向量化运算功能**，这是列表不具有的。\n",
    "\n",
    "在定义一维数组之前，我们需要先导入numpy包。用array定义一维数组，用dtype查看数据类型，数组的下标从零开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义：一维数组array\n",
    "a = np.array([2,3,4,5])#用列表定义一维数组\n",
    "\n",
    "#查看数据类型\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数组的访问有切片访问和循环访问两种，切片访问更常用，也更方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1:3]#切片。左闭右开原则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#循环访问\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas一维数组\n",
    "pandas包含两种数据类型：**series和dataframe**。\n",
    "\n",
    "**series是一种一维数据结构**，每一个元素都带有一个索引，与一维数组的含义相似，其中索引可以为数字或字符串。![jupyter](./img/intro-1.png)\n",
    "\n",
    "**dataframe是一种二维数据结构**，数据以表格形式（与excel类似）存储，有对应的行和列。dataframe结构名称：![jupyter](./img/intro-2.png)\n",
    "\n",
    "pandas一维数组可以用Series建立索引，用index来指定索引，这样，访问时就可以通过索引来访问数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas一维数据结构(有索引)，六家公司的股票，index为索引\n",
    "stockS = pd.Series([54.74,190.9,173.14,1050.3,181.86,1139.49],\n",
    "                  index = ['腾讯','阿里巴巴','苹果','谷歌','Facebook','亚马逊'])\n",
    "stockS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iloc属性用于根据位置获取值，loc属性用于根据索引获取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockS.iloc[0],stockS.loc['腾讯']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe用于获取描述统计信息。从结果来看，describe可以显示元素计数、均值、方差、最小值等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockS.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas一维数组也支持向量运算。在下图的向量运算中，结果出现了空值，这是因为运算中的某一个数据为空。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=pd.Series([1,2,3,4],index=['a','b','c','d'])\n",
    "s2=pd.Series([10,20,30,40],index=['a','b','e','f'])\n",
    "s3=s1+s2\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在运算中，我们经常不希望结果中出现空值，要想得到没有空值的结果，我们需要对数据进行处理。一种方式是将缺失值删除。pandas中用**dropna删除缺失数据**。第二种方法则是将缺失值进行填充，填充时，要根据实际情况，确定可以直接用零数据填充，还是需要建立模型，计算出填充值。pandas中用**add进行值的填充**，fill_value为填充值（下图填充值为0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=s1.add(s2,fill_value=0)\n",
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一维数组可视化时，索引号为横坐标，数据列的纵坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(100),index=pd.date_range('1/1/2000', periods=100))\n",
    "#ts = ts.cumsum()\n",
    "ts.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维数组\n",
    "### NumPy二维数组\n",
    "NumPy中，二维数组与一维数组的定义、查询及访问均非常类似。数组下标均从零开始，行号与列号用逗号分隔，行号在前，列号在后。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义二维数组\n",
    "b = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "#查询元素：行号与列号用逗号分隔，前面为行号，后面为列号\n",
    "b,b[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取第一行的元素\n",
    "b[0,:]\n",
    "#输出\n",
    "#array([1, 2, 3, 4])\n",
    "\n",
    "#获取第一列的元素\n",
    "b[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算平均值、最大最小值等统计值时，我们通常希望对每一行或者每一列求其统计值，而不是对整个数组求其统计值，这时就需要使用数轴参数axis。axis = 0表示按列计算，axis = 1表示按行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#按轴计算每一行的平均值\n",
    "b.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按轴计算每一列的平均值\n",
    "b.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas二维数组\n",
    "Numpy二维数组每一列的数据类型都是一样的，因此它不适合保存excel表格这样每一列的数据类型都不一样的数据。此时，pandas二维数组就可以发挥它的巨大作用了。\n",
    "\n",
    "pandas用**数据框DataFrame**定义二维数组，他有两个优点，一个是它每一列的数据类型都可以不一样，第二个是它每一行每一列都有一个索引，可以方便地通过索引访问数据。\n",
    "\n",
    "在用pandas数据框DataFrame定义带索引的二维数组时，**首先**要定义一个字典，映射列名和对应列的值；**其次**，定义数据框，将参数传入字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#定义字典映射列名和对应的值\n",
    "salesDict={\n",
    "    '购药时间':['2020-03-01 星期日','2020-03-02 星期一','2020-03-05 星期四'],\n",
    "    '社保卡号':['0012345','0023456','0034567'],\n",
    "    '商品名称':['VC银翘片','清热解毒口服液','感康'],\n",
    "    '商品编号':[98703,87602,65401],\n",
    "    '应收金额':[82.8,28,16.8]    \n",
    "}\n",
    "#定义数据库\n",
    "salesDf=pd.DataFrame(salesDict)\n",
    "salesDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas二维数组的数据访问与pandas一维数组类似。**iloc属性**用于根据位置查询值，**loc属性**用于根据索引查询值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesDf.iloc[0,1],salesDf.loc[0,'商品名称']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取第0列\n",
    "d0=salesDf.iloc[:,0]\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取商品名称列\n",
    "salesDf.loc[:,'商品名称'],salesDf['商品名称']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#查询某几列\n",
    "salesDf[['商品名称','应收金额']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候，我们需要根据**条件查询**出数组中符合条件的数据，这可以通过建立条件判断筛选和应用查询条件来实现。\n",
    "\n",
    "建立条件判断筛选："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querySer=salesDf.loc[:,'应收金额']>20\n",
    "type(querySer),querySer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "应用筛选条件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salesDf.loc[querySer,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面给出了可视化的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib as plt\n",
    "df = pd.DataFrame(np.random.randn(100, 4),index=ts.index, columns=list('ABCD'))\n",
    "#df = df.cumsum()\n",
    "#plt.figure();\n",
    "\n",
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y='B')#默认x轴为index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas基础\n",
    "参考：https://blog.csdn.net/weixin_44489066/article/details/89494395"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**从列表，数组，字典构建series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0\n",
       "b    1\n",
       "c    2\n",
       "e    3\n",
       "d    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np   # pandas和numpy常常结合在一起使用，导入numpy库\n",
    "import pandas as pd  # 导入pandas库\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')   # 列表\n",
    "myarr = np.arange(26)\t                      # 数组\n",
    "#del(dict)\n",
    "mydict = dict(zip(mylist, myarr))             # 字典(索引号、值)\n",
    "\n",
    "# 构建方法\n",
    "ser1 = pd.Series(mylist)\n",
    "ser2 = pd.Series(myarr)\n",
    "ser3 = pd.Series(mydict)\n",
    "ser3.head()    # 打印前5个数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使series的索引列转化为dataframe的列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(mydict)\n",
    "\n",
    "# series转换为dataframe\n",
    "df = ser.to_frame()\n",
    "# 索引列转换为dataframe的列\n",
    "df.reset_index(inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结合多个series组成dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建series1\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz')) \n",
    "# 构建series2\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "# 方法1，axis=1表示列拼接，0表示行拼接\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "# 与方法1相比，方法2设置了列名\n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**命名列索引的名称**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "\n",
    "# 命名索引列名称\n",
    "ser.name = 'alphabets'\n",
    "# 显示前5行数据\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获得数值series的四分位值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "state = np.random.RandomState(50)\n",
    "# 从均值为10标准差为5的正态分布随机抽取25个点构成series\n",
    "ser = pd.Series(state.normal(10, 5, 25))#均值、标准差、个数\n",
    "# 求ser的四分位数\n",
    "print(np.percentile(ser, q=[0, 25, 50, 75, 100]))\n",
    "#ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获得series中单一项的频率计数**，使用了take()函数：提取指定索引位置的数据,并以一维数组或者矩阵返回,如下示例：\n",
    "\n",
    "a = [4, 3, 5, 7, 6, 8]\n",
    "\n",
    "indices = [0, 1, 4]\n",
    "\n",
    "np.take(a, indices)\n",
    "\n",
    "array([4, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从0~7随机抽取30个列表值，组成series\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))#从第一个参数中提取数据，\n",
    "#print(ser)\n",
    "# 对该series进行计数\n",
    "print(ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'#保留series中前两个频次最多的项，其他项替换为‘other’\n",
    "#ser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对数值series分成10个相同数目的组**， 换个角度理解，对数值series离散化成10个类别（categorical）值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.random(30))\n",
    "#print(ser.head())\n",
    "# 离散化10个类别值,只显示前5行的数据\n",
    "pd.qcut(ser, q=[0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "           labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).value_counts()#.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使numpy数组转化为给定形状的dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "# serier类型转换numpy类型，然后重构\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取满足条件的索引和其位置的值**\n",
    "\n",
    "获取最大值索引：argmax() 、 idxmax ()\n",
    "\n",
    "获取最小值索引：argmin() 、 idxmin ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取值是3倍数的索引\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "index = ser[ser % 3==0].index# 获取值是3倍数的索引\n",
    "# 获取指定索引的元素\n",
    "print(ser,ser.argmax(),ser.take(index))\n",
    "#print(ser,ser[ser.argmax()],ser.argmin())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**垂直和水平的拼接series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "# 垂直拼接\n",
    "df = pd.concat([ser1, ser2], axis=0)\n",
    "\n",
    "# 水平拼接\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算两个series之间的欧氏距离**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "    \n",
    "# 方法1\n",
    "sum((p - q)**2)**.5\n",
    "    \n",
    "# 方法2\n",
    "np.linalg.norm(p-q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归一化dataframe的所有列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 青绿乌黑乌黑青绿浅白青绿乌黑乌黑乌黑青绿 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '青绿乌黑乌黑青绿浅白青绿乌黑乌黑乌黑青绿'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-fd6e8d3719ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwmDataDf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./DataSet/watermelon_3.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gbk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'色泽'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"密度\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"含糖率\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#读xlxs文件，GBK编码表示中文\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 正态分布归一化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwmDataDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Solution Q1\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[1;32m--> 296\u001b[1;33m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-fd6e8d3719ff>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwmDataDf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./DataSet/watermelon_3.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gbk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'色泽'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"密度\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"含糖率\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#读xlxs文件，GBK编码表示中文\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 正态分布归一化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwmDataDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Solution Q1\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11214\u001b[0m         return self._reduce(\n\u001b[1;32m> 11215\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11216\u001b[0m         )\n\u001b[0;32m  11217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3889\u001b[0m                 )\n\u001b[0;32m   3890\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3891\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3893\u001b[0m         \u001b[1;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    123\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1308\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                 \u001b[1;31m# e.g. \"foo\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Could not convert {x} to numeric\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 青绿乌黑乌黑青绿浅白青绿乌黑乌黑乌黑青绿 to numeric"
     ]
    }
   ],
   "source": [
    "wmDataDf=pd.read_csv('./DataSet/watermelon_3.csv',encoding='gbk',nrows=10,usecols=[\"密度\",\"含糖率\"])#读xlxs文件，GBK编码表示中文\n",
    "# 正态分布归一化\n",
    "out1 = wmDataDf.apply(lambda x: ((x - x.mean())/x.std()).round(2))\n",
    "print('Solution Q1\\n',out1)\n",
    "\n",
    "# 线性归一化\n",
    "out2 = wmDataDf.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2))\n",
    "print('Solution Q2\\n', out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**得到按列分组的dataframe的平均值和标准差**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         密度     含糖率\n",
      "色泽                 \n",
      "乌黑  0.59840  0.2182\n",
      "浅白  0.55600  0.2150\n",
      "青绿  0.48775  0.3205\n",
      "         密度     含糖率\n",
      "色泽                 \n",
      "乌黑  0.59840  0.2182\n",
      "浅白  0.55600  0.2150\n",
      "青绿  0.48775  0.3205\n"
     ]
    }
   ],
   "source": [
    "wmDataDf=pd.read_csv('./DataSet/watermelon_3.csv',encoding='gbk',nrows=10,usecols=['色泽',\"密度\",\"含糖率\"])#读xlxs文件，GBK编码表示中文\n",
    "# 按列col1分组后的平均值\n",
    "df_grouped_mean = wmDataDf.groupby(['色泽']).mean()\n",
    "print(df_grouped_mean)\n",
    "# 按列col1分组后的标准差\n",
    "df_grouped_std = wmDataDf.groupby(['色泽']).mean()\n",
    "print(df_grouped_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入/导出数据\n",
    "用python读取excel中的数据也非常方便。如果出现：Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd错误，是因为xlrd模块没有安装，执行pip install xlrd命令。\n",
    "\n",
    "如果出现No module named 'openpyxl'错误，安装相应模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#读取excel数据\n",
    "fileNameStr='./DataSet/20200707.xlsx'\n",
    "msgDf=pd.read_excel(fileNameStr,sheet_name='Sheet1')#读取文件 , shee_name是指定表单\n",
    "msgDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写入到文件\n",
    "msgDf.to_excel('./DataSet/20200707BAK.xlsx', sheet_name='Sheet1', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看行列数\n",
    "msgDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      密度    含糖率\n",
      "0  0.697  0.460\n",
      "1  0.774  0.376\n",
      "2  0.634  0.264\n"
     ]
    }
   ],
   "source": [
    "wmDataDf=pd.read_csv('./DataSet/watermelon_3.csv',encoding='gbk',nrows=3,usecols=[\"密度\",\"含糖率\"])#读xlxs文件，GBK编码表示中文\n",
    "print(wmDataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    编号  色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜  序关系\n",
      "0    1  青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是    1\n",
      "1    2  乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是    1\n",
      "2    3  乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是    1\n",
      "3    4  青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是    1\n",
      "4    5  浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是    1\n",
      "5    6  青绿  稍蜷  浊响  清晰  稍凹  软粘  0.403  0.237  是    1\n",
      "6    7  乌黑  稍蜷  浊响  稍糊  稍凹  软粘  0.481  0.149  是    1\n",
      "7    8  乌黑  稍蜷  浊响  清晰  稍凹  硬滑  0.437  0.211  是    1\n",
      "8    9  乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  0.666  0.091  否    0\n",
      "9   10  青绿  硬挺  清脆  清晰  平坦  软粘  0.243  0.267  否    0\n",
      "10  11  浅白  硬挺  清脆  模糊  平坦  硬滑  0.245  0.057  否    0\n",
      "11  12  浅白  蜷缩  浊响  模糊  平坦  软粘  0.343  0.099  否    0\n",
      "12  13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  0.639  0.161  否    0\n",
      "13  14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198  否    0\n",
      "14  15  乌黑  稍蜷  浊响  清晰  稍凹  软粘  0.360  0.370  否    0\n",
      "15  16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042  否    0\n",
      "16  17  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑  0.719  0.103  否    0\n"
     ]
    }
   ],
   "source": [
    "wmDataDf=pd.read_csv('./DataSet/watermelon_3.csv',encoding='gbk')#读xlxs文件，GBK编码表示中文\n",
    "print(wmDataDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmDataDf.to_csv('./DataSet/watermelonBAK.csv')\n",
    "data=wmDataDf.head()#默认读取前5行的数据\n",
    "data=wmDataDf.values#获取所有的数据\n",
    "data = df.columns.values #获取所有的列名 \n",
    "data = df.index.values #获取所有的行号 \n",
    "data=df.ix[0].values  #0表示第一行 这里读取数据并不包含表头\n",
    "data = df.ix[1,2] #读取第一行第二列的值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学公式与Numpy矩阵运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵初始化\n",
    "**Numpy矩阵初始化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myZeros=np.zeros([3,5])#3*5的全0矩阵\n",
    "print(\"myZeros\\n\",myZeros)\n",
    "myOnes=np.ones([3,5])#3*5的全1矩阵\n",
    "print(\"myOnes\\n\",myOnes)\n",
    "myRand=np.random.rand(3,5)#生成随机矩阵\n",
    "print(\"myRand\\n\",myRand)\n",
    "myEye=np.eye(3)#生成单位矩阵\n",
    "print(\"myEye\\n\",myEye)\n",
    "myMat=[[0,0,0,0,0],[0,1,2,3,4],[5,6,7,8,9]]#自定义矩阵\n",
    "print(\"myMat\\n\",myMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numpy之mat()创建矩阵**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "#创建一个3*3的零矩阵，矩阵这里zeros函数的参数是一个tuple类型(3,3)\n",
    "data1=mat(zeros((3,3)));\n",
    "#创建一个2*4的1矩阵，默认是浮点型的数据，如果需要时int类型，可以使用dtype=int\n",
    "data2=mat(ones((2,4)));\n",
    "data1,data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=mat(random.rand(2,2));\n",
    "#这里的random模块使用的是numpy中的random模块，\n",
    "#random.rand(2,2)创建的是一个二维数组，需要将其转换成#matrix\n",
    "\n",
    "data4=mat(random.randint(10,size=(3,3)));\n",
    "#生成一个3*3的0-10之间的随机整数矩阵，如果需要指定下界则可以多加一个参数\n",
    "\n",
    "data5=mat(random.randint(2,8,size=(2,5)));\n",
    "#产生一个2-8之间的随机整数矩阵\n",
    "\n",
    "data6=mat(eye(2,2,dtype=int));\n",
    "#产生一个2*2的对角矩阵\n",
    "\n",
    "a1=[1,2,3];\n",
    "a2=mat(diag(a1));\n",
    "#生成一个对角线为1、2、3的对角矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数组、矩阵、列表相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=[[1,2,3],[4,5,6]]#列表\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=array(a1)#列表转数组\n",
    "a2,a2[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3=mat(a1)#列表转矩阵\n",
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a5=a3.tolist()#矩阵转列表\n",
    "a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a6=list(a2)#数组转列表\n",
    "a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a7=array(a3)#矩阵转数组\n",
    "a7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵元素运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myMat+myOnes)#矩阵对应的元素加减运算\n",
    "print(myMat-myRand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常数乘矩阵，常数和矩阵中的每个数相乘。myMat是一个列表array，需要mat函数转换\n",
    "a=np.mat(myMat)\n",
    "print(10*a)\n",
    "\n",
    "b=np.array([1,2,3,4])\n",
    "#矩阵所有元素求和\n",
    "print(\"\\n\",sum(b),sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对array类型，是对所有元素求和；对于矩阵类型，默认是对列向量求和。如果是按行求和，要指定axis=1，默认axis=0是对列求和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\",np.sum(a,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵对应元素的**乘积**：对应元素相乘。维数不同时，根据广播机制进行扩充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.multiply(myOnes,myMat))#求对应位置的乘积\n",
    "c=np.ones([3,4])\n",
    "print(np.multiply(c,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以对矩阵每个元素进行运算，也可以进行矩阵的**乘法**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.power(myMat,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myEye*np.mat(myMat))#3*3的矩阵乘以3*5矩阵\n",
    "print([1,2,3]*np.mat(myMat))#向量乘以3*5矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵转置运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mat(myMat).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一维数组和切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个一维数组并初始化时，可以使用array函数，并用**列表**指定初始化的值。arange函数也可以产生一个指定元素个数的规则数组。结果中包含一个array关键字，表明是一个数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array ([10,20,30,40,50]) \n",
    "b=np.arange(10)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数组b长度为10，用数组名和索引号可以指定数组中的某个元素；用起始编号、终止编号（不含）、步长可以对数组**切片**，不指定步长时，默认为1片，即获取一个数组中的**部分数据**，参数之间用$:$分开，不指定步长时，默认为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[1],b[2:8:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将数组作为一个整体操作，如将数组b全部元素乘10，求a个元素的平方根等，得到的结果依然是一个数组。numpy的**abs、sqrt、square、log、log10、log2、rint等函数**可以对数组各元素进行绝对值、平方根、平方 、自然对数、以10和2为底的对数及四舍五入等运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b*10,np.sqrt(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着开始构造一个4x4的随机数组，因为产生的是随机数组，不同计算机的输出结果可能完全不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行的结果中有array，**表明是一个数组**，其中的每个元素是一个包含4个标量的列表,所以**matrix可以理解为数组的数组**。\n",
    "调用mat函数可以将数组转化为矩阵，.I操作是**求矩阵的逆**，如果没有numpy模块提供库函数的支持，求矩阵的逆将不会很容易。运行结果是两个矩阵，即maxtric。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randMat=np.mat(np.random.rand(4,4))\n",
    "randMat,randMat.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵和其逆矩阵相乘使用$*$符号，结果是一个单位矩阵，除了对角线为1，其它元素都是0。实际运行结果有些误差，用了一些非常小的值表示0，这是计算机不能精确处理任何数造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randMat*randMat.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "产生多维数组的方法用到了一维和二维数组的知识。如下分别定义了三维数组,产生了一个规则的三位数组。其中reshape将一维数组定义为2个3X4的二位数组，元素个数正好是24。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "y = np.arange(24).reshape((2, 3, 4)) \n",
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和一维数组类似，多维数组切片也是指定每一维的范围，如果包含某维的所有，则只使用$:$。使用范围时，采用左闭右开原则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:2,0:2],y[:,0:2,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "顺利完成上面的例子，说明已经安装了Numpy函数库，以后可以利用它们构造机器学习程序，并学习函数库更多的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy中的Linalg线性代数库\n",
    "NumPy 提供了线性代数函数库 linalg，该库包含了线性代数所需的所有功能。\n",
    "\n",
    "**numpy.dot()**对于两个**一维的数组**，计算这两个数组对应下标元素的**乘积和**(数学上称之为**内积**)；对于**二维数组**，计算的是两个数组的矩阵乘积；对于**多维数组**，它的通用计算公式如下，即结果数组中的每个元素都是：数组a的最后一维上的所有元素与数组b的倒数第二位上的所有元素的乘积和： dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[11,12],[13,14]])\n",
    "print(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy.vdot() ** 函数是两个向量的点积。 如果第一个参数是复数，那么它的共轭复数会用于计算。 如果参数是多维数组，它会被展开。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    " \n",
    "a = np.array([[1,2],[3,4]]) \n",
    "b = np.array([[11,12],[13,14]]) \n",
    " \n",
    "# vdot 将数组展开计算内积\n",
    "print (np.vdot(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy.inner()**函数返回一维数组的向量内积。对于更高的维度，它返回最后一个轴上的和的乘积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.inner(np.array([1,2,3]),np.array([0,1,0])))\n",
    "# 等价于 1*0+2*1+3*0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy.matmul()**函数返回两个数组的矩阵乘积。 虽然它返回二维数组的正常乘积，但如果任一参数的维数大于2，则将其视为存在于最后两个索引的矩阵的栈，并进行相应广播。\n",
    "\n",
    "另一方面，如果任一参数是一维数组，则通过在其维度上附加 1 来将其提升为矩阵，并在乘法之后被去除。\n",
    "\n",
    "对于二维数组，它就是矩阵乘法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,0],[0,1]] \n",
    "b = [[4,1],[2,2]] \n",
    "print (np.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy.linalg.det()**函数计算输入矩阵的行列式。\n",
    "\n",
    "行列式在线性代数中是非常有用的值。 它从方阵的对角元素计算。 对于 2×2 矩阵，它是左上和右下元素的乘积与其他两个的乘积的差。\n",
    "\n",
    "换句话说，对于矩阵[[a，b]，[c，d]]，行列式计算为 ad-bc。 较大的方阵被认为是 2×2 矩阵的组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]]) \n",
    " \n",
    "print (np.linalg.det(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy.linalg.inv()**函数计算矩阵的乘法逆矩阵。\n",
    "\n",
    "逆矩阵（inverse matrix）：设A是数域上的一个n阶矩阵，若在相同数域上存在另一个n阶矩阵B，使得： AB=BA=E ，则我们称B是A的逆矩阵，而A则被称为可逆矩阵。注：E为单位矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]]) \n",
    "y = np.linalg.inv(x) \n",
    "print (x)\n",
    "print (y)\n",
    "print (np.dot(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相似性度量\n",
    "两个n维向量之间的距离（此时向量为n维坐标系中的点），在数学上称为向量之间的距离distance，也称为样本之间的相似性度量。反映了某类事物在距离上接近或者远离的程度。距离越近的就越相似，越容易归为一类，距离越远越不同。在引入距离之前，我们先看看“范数”概念。\n",
    "\n",
    "**范数**（来自百度百科）：向量的范数可以简单、形象的理解为**长度**，或者向量**到坐标系原点的距离**，或者相应空间内**两点之间的距离**。\n",
    "\n",
    "向量的**范数定义**：向量的范数是一个函数$\\lVert x\\rVert$,满足非负性$\\lVert x\\rVert\\geq 0$，齐次性$\\lVert cx\\rVert=c\\lVert x\\rVert$,三角不等式$\\lVert x+y\\rVert\\leq\\lVert x\\rVert+\\lVert y\\rVert$。\n",
    "\n",
    "**L1范数**：$\\lVert x\\rVert$为**x向量**各个元素绝对值之和。\n",
    "\n",
    "**L2范数**：$\\lVert x\\rVert$为x向量各个元素的平方和的开方。L2范数又称**Euclidean范数**或者**Frobenius范数**。\n",
    "\n",
    "**Lp范数**：$\\lVert x\\rVert$为x向量各个元素绝对值p次方和的1/p次方。\n",
    "\n",
    "**L∞范数**：$\\lVert x\\rVert$为x向量各个元素绝对值最大的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向量A的范数，理解为A原点的距离\n",
    "A = [8,1,6]\n",
    "#手工计算方法\n",
    "modA = np.sqrt(sum(np.power(A,2)))\n",
    "#库函数方法\n",
    "normA = np.linalg.norm(A)\n",
    "print (\"modA:\",modA,\"\\nnorm(A):\",normA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各类距离的意义与Python代码的实现 　　\n",
    "**1.闵可夫斯基距离（Minkowski Distance）**\n",
    "\n",
    "两个n维变量$A(x_{11},x_{12},\\dots,x_{1n})$与$B(x_{21},x_{22},\\dots,x_{2n})$间的闵可夫斯基距离定义为：![jupyter](./Introduction-2.png)\n",
    "其中p是一个变参数\n",
    "\n",
    "当p=1时，就是**曼哈顿距离**\n",
    "\n",
    "当p=2时，就是**欧式距离**\n",
    "\n",
    "当p=∞时，就是**切比雪夫距离**\n",
    "\n",
    "根据变参数p的不同，闵可供夫斯基可以表示一类的距离。可以看到，严格意义上讲，闵可夫斯基距离不是一种距离，而是一组距离的定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.欧氏距离**\n",
    "\n",
    "欧氏距离即$L_2$范数，源自欧氏空间中两点之间的距离，如下图。\n",
    "\n",
    "二维平面上A、B两点之间的距离：$d_{12}=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$\n",
    "\n",
    "三维平面上A、B两点之间的距离：$d_{12}=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2}$\n",
    "\n",
    "n维平面上A、B两点之间的距离：$d_{12}=\\sqrt{\\sum_{k=1}^n(x_{1k}-x_{2k})^2}$\n",
    "\n",
    "表示为向量形式：$d_{12}=\\sqrt{(A-B)(A-B)^T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "vector1 = mat([1,2,3])\n",
    "vector2 = mat([4,5,6])\n",
    "print (sqrt((vector1-vector2)*((vector1-vector2).T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.曼哈顿距离**\n",
    "\n",
    "二维平面上A、B两点之间的距离：$d_{12}=|x_1-x_2|+|y_1-y_2|$\n",
    "\n",
    "n维平面上A、B两点之间的距离：$d_{12}=\\sum_{k=1}^n|x_{1k}-x_{2k}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sum(abs(vector1-vector2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.切比雪夫距离**\n",
    "\n",
    "类似于国际象棋从A到B的最少距离。计算公式$max(|x_2-x_1|,|y_2-y_1|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (abs(vector1-vector2).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.夹角余弦（Consine）**\n",
    "几何中的夹角余弦可用来**衡量两个向量方向的差异**![jupyter](./Introduction-3.bmp)二维平面两点$A(x_1,y_1)$与$B（x_2,y_2）$间的夹角余弦公式：![jupyter](./Introduction-4.bmp)两个n维样本点$A(x_{11},x_{12},\\dots,x_{1n})$与$B(x_{21},x_{22},\\dots,x_{2n})$的夹角余弦：![jupyter](./Introduction-5.bmp)即![jupyter](./Introduction-6.bmp)夹角余弦取值范围为[-1,1]。**夹角余弦越大，表示向量的夹角越小；夹角余弦越小，表示两个向量的夹角越大**。当两个向量的方向重合时，夹角余弦取最大值1；当两个向量的方向完全相反时，夹角余弦取值最小值-1.\n",
    "\n",
    "Python实现夹角余弦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosV12 = dot(vector1,vector2.T)/(linalg.norm(vector1)*linalg.norm(vector2))\n",
    "print (cosV12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.汉明距离（Hamming Distance）**\n",
    "\n",
    "汉明距离**定义**：两个等长的字符串s1和s2之间的汉明距离定义为将其中一个变为另外一个所需要的最小替换次数。例如字符串“111“与“1001”之间的汉明距离为2。\n",
    "\n",
    "应用：信息编码（为了增强容错性，应使编码间的最小汉明距离尽可能大）。\n",
    "\n",
    "使用Python实现汉明距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matV = mat([[1,1,0,1,0,1,0,0,1],[0,1,1,0,0,0,1,1,1]])\n",
    "smstr = nonzero(matV[0]-matV[1])\n",
    "smstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (shape(smstr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.杰卡德相似系数（Jaccard Similarity Coefficient）**\n",
    "\n",
    "**杰卡德相似系数**：两个集合A和B的交集元素在A、B的并集中所占的比例，成为两个集合的杰卡德相似系数，用符号J(A,B)表示。![jupyter](./Introduction-7.bmp)杰卡德相似系数是衡量两个集合的**相似度**的一种指标。\n",
    "\n",
    "**杰卡德距离**：与杰卡德相似系数相反的概念是杰卡德距离（Jaccard Distance），杰卡德距离可用如下的公式表示：![jupyter](./Introduction-8.bmp)杰卡德距离用两个集合中不同元素占所有元素的比例来衡量两个集合的**区分度**。\n",
    "\n",
    "杰卡德相似系数与杰卡德距离的应用:可将杰卡德相似系数用在衡量样本的相似度上。\n",
    "　　\n",
    "样本A与样本B是两个n维向量，而且所有维度上的取值都是0或者1。例如，A（0111）和B（1011）。我们将样本看成一个集合，1表示该集合包含该元素，0表示集合不包含该元素。\n",
    "　　\n",
    "P：样本A与B都是1的维度的个数\n",
    "\n",
    "q：样本A是1、样本B是0的维度的个数\n",
    "\n",
    "r: 样本A是0、样本B是1的维度的个数\n",
    "\n",
    "s：样本A与B都是0的维度的个数\n",
    "\n",
    "那么样本A与B的杰卡德相似系数可以表示为：![jupyter](./Introduction-9.bmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dist #导入Scipy距离公式\n",
    "matV = mat([[1,1,0,1,0,1,0,0,1],[0,1,1,0,0,0,1,1,1]])\n",
    "print (\"dist.jaccard:\",dist.pdist(matV,'jaccard'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机性与概率论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设一个集合，只有苹果和梨子两大类，各有10个，我们仅考察颜色特征，苹果有红色和黄色，其中红色8个；梨子也有两种颜色：黄色和绿色，其中黄色9个。我们用此例说明下面的概念。\n",
    "\n",
    "**样本**：原指随机实验的一个结果。可以理解为矩阵中的一个对象：苹果或者梨。\n",
    "\n",
    "**样本空间**：原指随机实验所有可能结果的集合，可以理解为矩阵的所有对象。引申为对象特征的取值范围：10个苹果，10个梨。\n",
    "\n",
    "**随机事件**:原指样本空间的一个子集，可以理解为某个分类，它实际指向一种概率分布：苹果为红色，梨为为黄色。\n",
    "\n",
    "**随机变量**：可以理解为指向某个事件的一个变量：$X\\{x_i=黄色\\}$\n",
    "\n",
    "**随机变量的概率分布**：给定随机变量的取值范围，导致某种随机事件出现的可能性。\n",
    "\n",
    "著名的贝叶斯公式：$$P(B|A)=\\frac{P(A|B)P(B)}{P(A)}$$\n",
    "\n",
    "用本节例子，求$p(梨|黄色)$,即挑选了一个黄色水果，问是梨的可能性。\n",
    "\n",
    "用贝叶斯公式$p(梨|黄色)=\\frac{P(黄色|梨)P(梨)}{P(黄色)}=\\frac{(9/10)*(10/20)}{11/20}=\\frac{9}{11}=81.8\\%$\n",
    "\n",
    "**多元统计**\n",
    "\n",
    "把水果的种类（取值为苹果、梨）和颜色（取值为红、黄、绿）看成对量的两个特征，这个随机向量的联合概率分布如下图\n",
    "![jupyter](./Introduction-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "白色部分表示水果和颜色两个特征的**联合概率分布**，灰色为两个特征各自取值的**边缘概率分布**。\n",
    "\n",
    "形式上，以二维随机变量为例，X、Y的**联合概率分布**为$$P\\{X=x_i,Y=y_j\\}=p_{ij}$$\n",
    "边缘概率分布为：$$P\\{X=x_1\\}=\\sum_{j=0}^{n}P_{1j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征间的相关性\n",
    "前面着重对矩阵行向量的划分，本节侧重对特征列的研究，研究在一个时间序列上观察到的两列数据之间的相关性。\n",
    "\n",
    "**期望**：衡量样本某个特征列取值范围的平均值。\n",
    "\n",
    "**方差**：衡量样本某个特征列取值范围离散程度。\n",
    "\n",
    "**协方差矩阵和相关系数**：衡量像本特征列之间的线性相关性。\n",
    "\n",
    "**1.相关系数**，定义为$$\\rho_{XY}=\\frac{Cov(X,Y)}{\\sqrt{D(X)}\\sqrt{D(Y)}}=\\frac{E((X-EX)(Y-EY))}{\\sqrt{D(X)}\\sqrt{D(Y)}}$$相关系数是衡量两个特征列之间相关程度的一种方法，范围为[-1,1]，绝对值越大，特征列X、Y的相关程度越高，当X和Y线性相关时，相关系数取1。\n",
    "\n",
    "**相关距离定义**：$D_{XY}=1-\\rho_{XY}$\n",
    "\n",
    "下面手工计算两个向量的相关系数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "matV = mat([[1,1,0,1,0,1,0,0,1],[0,1,1,0,0,0,1,1,1]])#两个向量\n",
    "mv1 = mean(matV[0])#第一列的均值\n",
    "mv2 = mean(matV[1])#第二列的均值\n",
    "#计算两列的标准差\n",
    "dv1 = std(matV[0])\n",
    "dv2 = std(matV[1])\n",
    "corref=mean(multiply(matV[0]-mv1,matV[1]-mv2))/(dv1*dv2)\n",
    "print (corref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Numpy**相关系数corrcoef**得到相关系数矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrcoef(matV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数矩阵是对称矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.马氏距离**\n",
    "\n",
    "**马氏距离的定义**：有M个样本向量$X_1-X_m$，协方差矩阵记为S，均值记为向量μ，则其中样本向量X到μ的距离为：$$D(X)=\\sqrt{(X-μ)^TS^{-1}(X-μ)}$$\n",
    "而其中$X_i$与$X_j$之间的马氏距离为：$$D(X_i，X_j)=\\sqrt{(X_i-X_j)^TS^{-1}(X_i-X_j)}$$\n",
    "若协方差矩阵是**单位矩阵**（各个样本向量之间独立同分布），则公式变成欧式距离公式：$$D(X_i，X_j)=\\sqrt{(X_i-X_j)^T(X_i-X_j)}$$\n",
    "若协方差是**对角矩阵**，则公式变成可标准化的欧式距离公式\n",
    "\n",
    "马氏距离的优点：量纲无关，排除变量之间的相关性的干扰。\n",
    "\n",
    "马氏距离计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "matV = mat([[1,1,0,1,0,1,0,0,1],[0,1,1,0,0,0,1,1,1]])\n",
    "coninv = linalg.inv(cov(matV))#先求协方差矩阵，再求逆\n",
    "tp =matV.T[0]-matV.T[1]\n",
    "distma = sqrt(dot(dot(tp,coninv),tp.T))\n",
    "distma = sqrt(dot(dot(tp,coninv),tp.T))\n",
    "distma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵空间变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在几何或物理上，向量都是一个有方向、有大小的量，其坐标不过是表征该向量与坐标系原点的距离，以及与坐标轴的夹角而已。\n",
    "\n",
    "在一个向量空间中，必须给定一个坐标系（不一定正交），方便定位和向量。**基底向量**对应坐标系轴，n维空间中有n个基底。\n",
    "\n",
    "由基底构成的空间内部的任何向量都可以由基底来线性表示。一个空间中，基底不是唯一的，在一组基底空间中表示的向量，用另外一组基底表示时，就需要**空间变换**。变换时使用矩阵乘法进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征值和特征向量\n",
    "$$Av=\\lambda v$$\n",
    "$A$是原矩阵，$v$是特征向量，$\\lambda$特征值。\n",
    "\n",
    "求取矩阵的特征值和特征向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = mat([[8,1,6],[3,5,7],[4,9,2]])\n",
    "print(A)\n",
    "evals,evecs = linalg.eig(A)#返回包含特征值和对应的特征向量的元组\n",
    "print ('特征值:',evals,'\\n特征向量:',evecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了特征值和特征向量，我们可以还原出原来的矩阵：$$A=Q\\Sigma Q^{-1}$$A$是原矩阵，$Q$是特征向量，$\\Sigma $是特征值构成的对角矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs*diag(evals)*linalg.inv(evecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=evals*eye(3)\n",
    "print(sigma)\n",
    "print (evecs*sigma*linalg.inv(evecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据归一化\n",
    "归一化一种简化计算计算的方式，即将有量纲表达式，经过转换称为无量纲的表达式，称为标量。归一化机器学习的基础工作。\n",
    "\n",
    "归一化两种方式，一种是把数据变为(0,1)之间的小数，这是统计的概率分布，如在(-1,+1)之间，则是统计的坐标分布。另一种是把有量纲的表达式变为无量纲的表达式，如身高、体重没有可比性，但是身高/体重的比值可能就具有可比性了。\n",
    "\n",
    "**数据标准化**：归一化的一种形式，本质上也是消除量纲的差异。主要方法是按比例缩放，使之落入一个小的特定区间。由于特征向量的各个特征的度量单位不同，为了使特征之间参与评价计算，需要对特征做规范化处理。\n",
    "\n",
    "**对欧式距离的标准化**：是对**简单欧式距离**的一种改进。**其思路**：既然数据的各维分量的fe内部不一样，就先将各个分量都标准化到均值、方差等。而且，标准化变量的均值为0，方差为1。因此，样本集的**标准化过程**是：$$X^*=\\frac{X-M}{S}$$\n",
    "M为分量的均值，S为方差。\n",
    "\n",
    "两个n维变量$A(x_{11},x_{12},\\dots,x_{1n})$与$B(x_{21},x_{22},\\dots,x_{2n})$之间de 标准化欧式距离：$$d_{12}=\\sqrt{\\sum_{k=1}^n(\\frac{X_{1k}-X_{2k}}{S_k})^2}$$如果将方差的倒数kancheng 权重，可以将之视为一种加权欧式距离。\n",
    "\n",
    "标准化欧式距离Python的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "vectormat = mat([[1,2,3],[4,5,6]])\n",
    "v12 = vectormat[0]-vectormat[1]\n",
    "print (sqrt(v12*v12.T))\n",
    "#norm\n",
    "varmat = std(vectormat.T,axis=0)\n",
    "normvmat =(vectormat-mean(vectormat))/varmat.T\n",
    "normv12 =normvmat[0]-normvmat[1]\n",
    "sqrt( normv12* normv12.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#曲线数据加入噪声\n",
    "x = np.linspace(-5,5,200)\n",
    "y = np.sin(x)  #给出y与x的基本关系\n",
    "\n",
    "yn = y+np.random.rand(1,len(y))*1.5#加入噪声的点集\n",
    "#绘图\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x,yn,c='blue',marker='o')\n",
    "ax.plot(x,y+0.75,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python 3 系统默认使用的就是utf-8编码。 \n",
    "#import sys\n",
    "#import os\n",
    "from numpy import *\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8') \n",
    "#数据文件转矩阵\n",
    "#参数：路径文件.\n",
    "def file2matrix(file):\n",
    "    recordlist=[]\n",
    "    fp=open(file,\"r\")\n",
    "    lines=fp.readlines()#全部都，将txt文件转换为所有的行组成的列表  \n",
    "    fp.close()\n",
    "    for line in lines:\n",
    "        recordlist.append(line.split('\\t'))#按行转化为一维表\n",
    "    return mat(recordlist)\n",
    "\n",
    "root=\"abalone.txt\"\n",
    "recordmat=file2matrix(root)\n",
    "print(shape(recordmat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对象持久化pickle\n",
    "有时候，我们希望数据以对象的方式保存。Python提供了cPicke模块支持对象的读写。在python2.X中，需要安装cPickle，在python3.X中，这个包已被别的包替换，使用以下语句即可：\n",
    "import _pickle as cPickle。\n",
    "\n",
    "pikcle的作用是编码和解码。pikcle的四种方法:\n",
    "\n",
    "dump    对文件中的内容进行编码操作\n",
    "\n",
    "load    对文件中的内容进行解码操作\n",
    "\n",
    "dumps   将内容编码成二进制的方式\n",
    "\n",
    "loads   将内容从二进制上进行解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先进行调用pickle模块\n",
    "import _pickle as pickle\n",
    "list1=[1,2,3,4]\n",
    "res=pickle.dumps(list1) #:将列表内容转换成二进制\n",
    "print(res)\n",
    "res1=pickle.loads(res)\n",
    "print(res1)\n",
    "\n",
    "\n",
    "#使用pikcle对文件进行写读操作(二进制)\n",
    "#注意必须要使用二进制的方式进行操作\n",
    "# import  pickle\n",
    "with open(\"pick_test.txt\",\"wb\") as file1:\n",
    "     pickle.dump(\"天上天下，人来人往\",file1)\n",
    "with open(\"pick_test.txt\",\"rb\") as file1:\n",
    "     res=pickle.load(file1)\n",
    "     print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安装数据包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**安装更新Numpy数据包**\n",
    "在anaconda环境下，启动命令shell，安装numpy命令：conda install numpy，或者pip install numpy,更新命令conda update numpy。\n",
    "\n",
    "**安装Scipy数据包**\n",
    "\n",
    "**安装matplotlib数据包**\n",
    "\n",
    "**安装scikit-learn数据包**\n",
    "\n",
    "sklearn是机器学习中一个常用的python第三方模块，对一些常用的机器学习方法进行了封装，在进行机器学习任务时，并不需要实现所有的算法，只需要简单的调用sklearn里的模块就可以实现大多数机器学习任务。\n",
    "机器学习任务通常包括**分类（Classification）和回归（Regression）**，常用的分类器包括**SVM、KNN、贝叶斯、线性回归、逻辑回归、决策树、随机森林、xgboost、GBDT、boosting、神经网络NN**。\n",
    "\n",
    "常见的降维方法包括**TF-IDF、主题模型LDA、主成分分析PCA**等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**安装jieba数据包**：在中文分词系统方面，后面部分章节需要用到。这里尽量使用小巧高效而且原生支持python的系统，推荐使用jieba分词，它是专门使用python语言开发的分词系统，占用资源小，常识类文档的分词精度比较高，对于非专业文档绰绰有余。\n",
    "\n",
    "安装命令：pip install jieba\n",
    "\n",
    "下面给出一个样例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import jieba\n",
    "\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')#设置UTF-8 Unicode环境\n",
    "\n",
    "seg_list=jieba.cut(\"小明1995年毕业于中华人民共和国北京中国人民大学\",cut_all=False)\n",
    "print (\"默认模式：\",\" \".join(seg_list))#默认切分\n",
    "\n",
    "seg_list=jieba.cut(\"小明1995年毕业于中华人民共和国北京中国人民大学\",cut_all=True)\n",
    "print (\"全切分：\",\" \".join(seg_list))#全切分\n",
    "\n",
    "seg_list=jieba.cut(\"小明1995年毕业于中华人民共和国北京中国人民大学\")\n",
    "print (\"搜索模式：\",\"， \".join(seg_list))#搜索引擎模式"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
