{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习基础知识\n",
    "**参考：《动手深度学习》，李沐**https://mxnet.apache.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXNET介绍\n",
    "MXNet是主流的三大深度学习框架之一：\n",
    "\n",
    "**TensorFlow**：Google支持，其简化版是Keras；\n",
    "\n",
    "**PyTorch**：Facebook支持，其工业版是Caffe2；\n",
    "\n",
    "**MXNet**：中立，Apache孵化器项目，也被AWS选为官方DL平台；\n",
    "\n",
    "MXNet的**优势**是，其开发者之一**李沐**，是中国人，在MXNet的推广中具有语言优势（汉语），有利于国内开发者的学习。同时，推荐李沐录制的教学视频，非常不错。\n",
    "\n",
    "MXNet的高层接口是**Gluon**，Gluon同时支持灵活的动态图和高效的静态图，既保留动态图的易用性，也具有静态图的高性能，这也是官网介绍的flexible和efficient的出处。同时，MXNet还具备大量学术界的前沿算法，方便移植至工业界。希望MXNet团队再接再励，在深度学习框架的竞赛中，位于前列。\n",
    "\n",
    "直接使用pip安装MXNet即可：**pip install mxnet**\n",
    "\n",
    "如果下载较慢，可以配置清华PyPI镜像（如⽆法运⾏，将pip版本升级到>=10.0.0）\n",
    "pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据操作\n",
    "在深度学习中，我们通常会频繁地对数据进⾏操作。作为动⼿学深度学习的基础，本节将介绍如何对内存中的数据进⾏操作。\n",
    "\n",
    "在 MXNet 中，NDArray 是存储和变换数据的主要⼯具。如果你之前⽤过 NumPy，你会发现 NDArray 和 NumPy 的多维数组⾮常类似。然而，NDArray 提供诸如 GPU 计算和⾃动求导在内的更多功能。这些都使得 NDArray 更加适合深度学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建 NDArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDArray 是 MXNet 中存储和变换数据的主要⼯具，我们先介绍 NDArray 的最基本功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
       "<NDArray 10 @cpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import nd#导入ndarray模块\n",
    "x=nd.arange(10)#⽤arange函数创建⼀个ndarray实例，也是一个⾏向量。\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果出现错误，则提示错误信息ModuleNotFoundError表示，mxnet模块没有安装。\n",
    "\n",
    "如果你的电脑上有 Nvidia 显卡并安装了 CUDA，建议使⽤ GPU 版的 MXNet，conda进行安装命令为conda install -c anaconda mxnet-gpu。\n",
    "\n",
    "从打印 x 时显⽰的属性<NDArray 10 @cpu(0)> 可以看到，它是⻓度为 10 的⼀维数组，且被创建在 CPU 主内存上，CPU ⾥⾯的 0 没有特别的意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape#通过 shape 属性来获取 NDArray 实例形状。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 **size 属性**得到 NDArray 实例中元素的总数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使⽤ **reshape 函数**把向量 x 的形状改为（2，5），也就是⼀个 2 ⾏ 5 列的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 1. 2. 3. 4.]\n",
       " [5. 6. 7. 8. 9.]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了形状改变之外，x 中的元素保持不变。\n",
    "x 属性中的形状发⽣了变化。上⾯ x.reshape((2, 5)) 也可写成 x.reshape((-1,5)) 或 x.reshape((2, -1))。由于 x 的元素个数是已知的，-1表明通过元素个数和其他维度的⼤小推断。\n",
    "接下来，我们创建⼀个各元素为 0，形状为（2，3，4）的**张量**。实际上，之前创建的向量和矩阵都是特殊的张量。张量这一术语起源于力学，它最初是用来表示弹性介质中各点应力状态的，数学上，**张量概念是矢量概念的推广**，如矢量就是一阶张量，本例可以理解为2个3*4矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0.]]\n",
       "\n",
       " [[0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0.]]]\n",
       "<NDArray 2x3x4 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似地，我们可以创建各元素为 1 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1. 1.]\n",
       " [1. 1. 1. 1.]\n",
       " [1. 1. 1. 1.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.ones((3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以通过 **Python 的列表（list）**指定需要创建的 NDArray 中每个元素的值。[]符号里面的若干数字表示一个列表，列表是可以嵌套的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 2. 3. 4. 5.]\n",
       " [5. 4. 3. 2. 1.]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nd.array([[1,2,3,4,5],[5,4,3,2,1]])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些情况下，我们需要随机⽣成 NDArray 中每个元素的值。下⾯我们创建⼀个形状为（3，4）的\n",
    "NDArray。它的每个元素都**随机采样于均值为 0 标准差为 1 的正态分布**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.68106437 -0.1353156   0.37723133  0.41016456]\n",
       " [ 0.5712682  -2.7579627   1.07628    -0.6141325 ]\n",
       " [ 1.8307649  -1.1468065   0.05383794 -2.5074806 ]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.random.normal(0, 1, shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运算 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDArray ⽀持⼤量的运算符（operator）。例如，我们可以对之前创建的两个形状为 (2, 5) 的 NDArray 做按元素加法。所得结果形状不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0. 1. 2. 3. 4.]\n",
      " [5. 6. 7. 8. 9.]]\n",
      "<NDArray 2x5 @cpu(0)> \n",
      "[[1. 2. 3. 4. 5.]\n",
      " [5. 4. 3. 2. 1.]]\n",
      "<NDArray 2x5 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  3.  5.  7.  9.]\n",
       " [10. 10. 10. 10. 10.]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x,y)\n",
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是**按照元素的乘法和除法**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[ 0.  2.  6. 12. 20.]\n",
       "  [25. 24. 21. 16.  9.]]\n",
       " <NDArray 2x5 @cpu(0)>,\n",
       " \n",
       " [[0.        0.5       0.6666667 0.75      0.8      ]\n",
       "  [1.        1.5       2.3333333 4.        9.       ]]\n",
       " <NDArray 2x5 @cpu(0)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y,x/y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照元素做指数运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[  2.7182817   7.389056   20.085537   54.59815   148.41316  ]\n",
       " [148.41316    54.59815    20.085537    7.389056    2.7182817]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除去按元素计算外，我们还可以使用**dot函数做矩阵乘法运算**。下⾯将 x 与 y 的转置做矩阵乘法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 40.  20.]\n",
       " [115.  95.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.dot(x,y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以将多个 NDArray 合并。下⾯分别在⾏上（**维度 0**，即形状中的最左边元素）和列上（**维度 1**，即形状中左起第⼆个元素）连结concatenate两个矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[0. 1. 2. 3. 4.]\n",
       "  [5. 6. 7. 8. 9.]\n",
       "  [1. 2. 3. 4. 5.]\n",
       "  [5. 4. 3. 2. 1.]]\n",
       " <NDArray 4x5 @cpu(0)>,\n",
       " \n",
       " [[0. 1. 2. 3. 4. 1. 2. 3. 4. 5.]\n",
       "  [5. 6. 7. 8. 9. 5. 4. 3. 2. 1.]]\n",
       " <NDArray 2x10 @cpu(0)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.concat(x, y, dim=0), nd.concat(x, y, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使⽤条件判断式可以得到元素为 0 或 1 的新的 NDArray。以 x == y 为例，如果 x 和 y 在相\n",
    "同位置的条件判断为真（值相等），那么新 NDArray 在相同位置的值为 1；反之为 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. 0. 0.]\n",
       " [1. 0. 0. 0. 0.]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x==y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 NDArray 中的所有元素求和得到只有⼀个元素的 NDArray，结果是一个只有一个元素的列表p[45.]，而不是一个简单的标量。要得到标量，可是使用**asscalar函数**。norm()是求x的$L_2$范数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [45.]\n",
       " <NDArray 1 @cpu(0)>,\n",
       " 45.0,\n",
       " 16.881943)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(),x.sum().asscalar(),x.norm().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "也可以把Y.exp()、X.sum()、X.norm()等分别改写为nd.exp(Y)、nd.sum(X)、nd.norm(X)等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广播机制 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前⾯我们看到如何对两个形状相同的 NDArray 做按元素操作。当对两个形状不同的 NDArray 做同样操作时，可能会触发⼴播（broadcasting）机制：**先适当复制元素使得这两个 NDArray 形状相同后再按元素操作**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[0.]\n",
       "  [1.]\n",
       "  [2.]]\n",
       " <NDArray 3x1 @cpu(0)>,\n",
       " \n",
       " [[0. 1.]]\n",
       " <NDArray 1x2 @cpu(0)>,\n",
       " \n",
       " [[0. 1.]\n",
       "  [1. 2.]\n",
       "  [2. 3.]]\n",
       " <NDArray 3x2 @cpu(0)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.arange(3).reshape((3, 1))\n",
    "b = nd.arange(2).reshape((1, 2))\n",
    "a,b,a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 a 和 b 分别是 3 ⾏ 1 列和 1 ⾏ 2 列的矩阵，如果要计算 a+b，那么 a 中第⼀列的三个元\n",
    "素被⼴播（复制）到了第⼆列，而 b 中第⼀⾏的两个元素被⼴播（复制）到了第⼆⾏和第三⾏。\n",
    "如此，我们就可以对两个 3 ⾏ 2 列的矩阵按元素相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 NDArray 中，索引（index）代表了元素的位置。NDArray 的索引从 0 开始逐⼀递增。例如⼀\n",
    "个 2 ⾏ 5 列的矩阵的⾏索引分别为 0、1 ，列索引分别为 0 、1、2、3、4。单个元素位置用行号和列号表示。\n",
    "\n",
    "在下⾯的例⼦中，我们指定了 NDArray 的⾏索引截取范围 [0:1]。依据**左闭右开**指定范围的惯例，x[0:1]截取了矩阵 x 中⾏索引为 0的⾏,x[0:2,2:4]用行索引和列索引指定了x的一个区域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [3.]\n",
       " <NDArray 1 @cpu(0)>,\n",
       " \n",
       " [[0. 1. 2. 3. 4.]]\n",
       " <NDArray 1x5 @cpu(0)>,\n",
       " \n",
       " [[2. 3.]\n",
       "  [7. 8.]]\n",
       " <NDArray 2x2 @cpu(0)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][3],x[0:1],x[0:2,2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要指定单个元素的位置，可以指定一个行索引和列索引,如 x[1,3]=10。也可以指定一个范围，一次性重设它们的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1. 10. 10.  4.]\n",
       " [ 5.  6. 10. 10.  9.]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2,2:4]=10\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行的内存开销 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前⾯例⼦中，对每个操作都要新开内存来储存它的结果。例如y = x + y， 会为y新创建内存。如果现有的 NDArray 的值在之后的程序中不会复⽤，我们也可以⽤ x[:] = x + y 或者 x +=y 来减少运算的内存开销。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=nd.arange(6).reshape((2,3))\n",
    "b=nd.ones((2,3))\n",
    "before=id(a)#id为numpy自带的内存地址函数\n",
    "a=a+b\n",
    "id(a)==before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before=id(a)\n",
    "a[:]=a+b\n",
    "id(a)==before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDARRAY和NumPy互换 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过**array 和 asnumpy 函数**令数据在 NDArray 和 NumPy 格式之间相互转换。下⾯将NumPy 实例变换成 NDArray 实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1.]\n",
       " [1. 1. 1.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "p = np.ones((2, 3))\n",
    "d = nd.array(p)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再将 NDArray 实例变换成 NumPy 实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动求梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习中，我们经常需要对函数求梯度（gradient）。本小节将介绍梯度上升法，并使⽤**MXNet 提供的 autograd包**来⾃动求梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度上升法 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度上升法是一种**优化算法**。其**基本思想**是，要找到某函数的最大值，最好的方法就是沿着该函数的梯度方向探寻。如果记梯度为$\\nabla$，简单函数$f(x_1,x_2)$的梯度由下式表示：$$\\left[\\begin{array} {cccc}\n",
    "\\frac{\\partial{f(x_1,x_2)}}{\\partial{x_1}}\\\\  \\frac{\\partial{f(x_1,x_2)}}{\\partial{x_2}}\\\\\n",
    "\\end{array} \\right] $$\n",
    "数学上，假设函数$f:R^n\\rightarrow R$的输入是一个$n$维变量， $ \\left[ \\begin{array} {cccc}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "\\ldots \\\\\n",
    "x_n\n",
    "\\end{array} \\right]$，\n",
    "输出是标量，函数$f$有关$x$的梯度是一个由$n$个偏导数组成的向量：$$\\nabla_xf(x)=\\nabla f(x)= \\left[\\begin{array} {cccc}\n",
    "\\frac{\\partial{f(x)}}{\\partial{x_1}}\\\\  \\frac{\\partial{f(x)}}{\\partial{x_2}}\\\\ \\ldots \\\\ \\frac{\\partial{f(x)}}{\\partial{x_n}}\\\\\n",
    "\\end{array} \\right] $$\n",
    "假设$x$是一个**向量**，**常见的梯度演算**包括：$$\\nabla_xA^Tx=A,\\\\ \\nabla_x x^TA=A,\\\\\\nabla_x x^TAx=(A+A^T)x,\\\\ \\nabla_x\\parallel x \\parallel^2=\\nabla_xx^Tx=2x.$$\n",
    "类似地，假设$X$是一个**矩阵**，那么：$$\\nabla_X\\parallel x \\parallel_F ^2=2X.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以函数$f(x_1,x_2)$为例，要求该函数的极值，使用梯度意味着，要沿$x_1$方向移动$\\frac{\\partial{f(x_1,x_2)}}{\\partial{x_1}}$，要沿$x_2$方向移动$\\frac{\\partial{f(x_1,x_2)}}{\\partial{x_2}}$。其中，函数$f(x_1,x_2)$要在待计算的点上有定义并且可微。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度上升算法每次沿着**梯度方向**移动一步，每次移动总是朝着函数增长最快的方向。每次移动的多少称为一个**步长**，记为$a$，用向量来表示的话，梯度算法就是一个迭代公式：$$w=w+a\\nabla _wf(w)$$\n",
    "该函数一直被迭代执行，直到满足某个**截至条件**为止，比如达到指定的迭代次数或者算法达到某个允许的误差范围。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降法 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度上升法用来求函数的极大值，梯度下降法用来求函数的极小值。它们的迭代公式一样，只是梯度下降法中的加号变成了减号。通过符号的变换，求极大值就转换为求极小值。\n",
    "梯度下降算法是常用的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求梯度实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对函数$y=2x^Tx$求关于**向量$x$**的梯度。为了求有关变量 x 的梯度，我们需要先调⽤ **attach_grad 函数**来申请存储梯度所需要的内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd,nd\n",
    "x = nd.arange(4).reshape((4, 1))#创建变量，并赋初值\n",
    "x.attach_grad()#调⽤attach_grad函数来申请存储梯度所需要的内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下⾯**定义有关变量 x 的函数**。为了减少计算和内存开销，默认条件下 MXNet 不会记录⽤于求梯度的计算。我们需要调⽤record 函数来要求 MXNet 记录与求梯度有关的计算。接下来我们可以通过调⽤ **backward 函数⾃动求梯度**。需要注意的是，如果y不是⼀个标量，MXNet将默认先对y中元素求和得到新的变量，再求该变量有关x的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 4.]\n",
       " [ 8.]\n",
       " [12.]\n",
       " [16.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = 2 * nd.dot(x.T, x)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的例子中我们可以发现，当我们需要计算多个变量的梯度时，只要运行对应变量的**.grad** 即可。\n",
    "\n",
    "涉及到**with语句**。简单来说，**with提供了一种资源管理的方式**。资源的管理在程序设计中是一个很常见的问题，例如管理开启的文件、网络 socket 和各种锁（locks）等。最主要的问题就在于我们必须确保这些开启的资源在使用完之后，确实被关闭或释放。如果忘记关闭这些资源，可能会造成程序执行上的效能问题，甚至出现错误。而除了关闭之外，有些特殊的资源在使用完毕之后，还必须进行一些后续的清理操作，这些也都是资源管理上需要注意的。\n",
    "\n",
    "Python 语言提供了 with 这个独特的语法，可让程序设计者更容易管理这些开启的资源，在这样的语法架构之下，Python 程序会自动进行资源的建立、清理与回收动作，让程序设计者在使用各种资源时更为方便。\n",
    "\n",
    "下面举一个简单的使用文件资源的例子。当我们需要使用一个文件资源，可能会这样写：\n",
    "\n",
    "f = open(filename)#开启\n",
    "\n",
    "...\n",
    "\n",
    "f.close()#关闭\n",
    "\n",
    "这种写法会有一个问题，如果在使用文件的过程中发生了一些意外状况，造成程序提早跳开时，这个开启的文件就没有被关闭。所以比较好的写法是使用 try 与 finally：\n",
    "\n",
    "f = open(filename)#开启\n",
    "\n",
    "try:\n",
    "\n",
    "\t...\n",
    "    \n",
    "finally:\n",
    "\t\n",
    "\tf.close()# 关闭\n",
    "    \n",
    "上面这种写法虽然不会有问题，但是**缺点**就是必须手动加入关闭文件的代码，不是很方便，也很容易忘记。with则可以解决上述问题，使用 with 开启文件时，会将开启的文件放在 f 变量中。 f 只有在 with 的范围内使用，**离开范围时就会自动被关闭，回收相关的资源**。 \n",
    "#开启\n",
    "\n",
    "with open(filename) as f:\n",
    "\n",
    "\tf.write(\"hello mxnet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模式和预测模式\n",
    "从上⾯可以看出，在调⽤record函数后，MXNet会记录并计算梯度。此外，默认情况下autograd还会将运⾏模式从预测模式转为训练模式。这可以通过调⽤**is_training函数**来查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- A Simple Example -------\n",
      "\n",
      "[[ 0.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [12.]]\n",
      "<NDArray 4x1 @cpu(0)>\n",
      "\n",
      "------- Different Mode Detection -------\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd, autograd\n",
    "print('------- A Simple Example -------')\n",
    "# 求解函数：y=2(X^T)X关于列向量X的梯度\n",
    "X = nd.arange(4).reshape(4, 1)              # 创建列向量\n",
    "X.attach_grad()                             # 调用attach_grad函数申请存储梯度的内存\n",
    "with autograd.record():\n",
    "    y = 2 * nd.dot(X.T, X)                  # 定义函数y。record函数要求MXNet记录与求梯度相关的计算，默认条件不计算\n",
    "\n",
    "y.backward()                                # backward函数用于自动求梯度。y若不是标量，MXNet将对y所有元素求和得到新变量，再求这个变量关于X的梯度\n",
    "\n",
    "assert (X.grad - 4 * X).norm().asscalar() == 0  # 验证梯度是否为4X\n",
    "print(X.grad)                                   # 输出结果也是NDArray格式\n",
    "\n",
    "\n",
    "print('\\n------- Different Mode Detection -------')\n",
    "# 默认autograd会将运行模式从预测模式转换为训练模式，可通过函数is_training查看\n",
    "print(autograd.is_training())\n",
    "with autograd.record():\n",
    "    print(autograd.is_training())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其它\n",
    "想知道⼀个模块⾥⾯提供了哪些可以调⽤的函数和类的时候，可以使⽤dir函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NDArray', '_Null', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_internal', '_random_helper', 'current_context', 'exponential', 'exponential_like', 'gamma', 'gamma_like', 'generalized_negative_binomial', 'generalized_negative_binomial_like', 'multinomial', 'negative_binomial', 'negative_binomial_like', 'normal', 'normal_like', 'numeric_types', 'poisson', 'poisson_like', 'randint', 'randn', 'shuffle', 'uniform', 'uniform_like']\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "print(dir(nd.random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过成员的名字我们⼤致猜测出这个模块提供了各种随机数的⽣成⽅法，包括从均匀分布采样（uniform）、从正态分布采样（normal）、从泊松分布采样（poisson）等。\n",
    "\n",
    "查找特定函数和类的使⽤。想了解某个函数或者类的具体⽤法时，可以使⽤help函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ones_like:\n",
      "\n",
      "ones_like(data=None, out=None, name=None, **kwargs)\n",
      "    Return an array of ones with the same shape and type\n",
      "    as the input array.\n",
      "    \n",
      "    Examples::\n",
      "    \n",
      "      x = [[ 0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.]]\n",
      "    \n",
      "      ones_like(x) = [[ 1.,  1.,  1.],\n",
      "                      [ 1.,  1.,  1.]]\n",
      "    \n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : NDArray\n",
      "        The input\n",
      "    \n",
      "    out : NDArray, optional\n",
      "        The output NDArray to hold the result.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : NDArray or list of NDArrays\n",
      "        The output of this function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nd.ones_like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读者也可以在MXNet的⽹站上查阅相关⽂档。访问MXNet⽹站 https://mxnet.apache.org/。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
